{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"IRENA FlexTool tutorial IRENA FlexTool is an energy systems optimisation model developed for power and energy systems with high shares of wind and solar power. It can be used to find cost-effective sources of flexibility across the energy system to mitigate the increasing variability arising from the power systems. It can perform multi-year capacity expansion as well as unit commitment and economic dispatch in a user-defined sequence of solves. The aim has been to make it fast to learn and easy to use while including lot of functionality especially in the time scales relevant for investment planning and operational scheduling of energy systems. The instructions for installing IRENA FlexTool are here . This user guide will build a small system step-by-step. It assumes you will be using Spine Toolbox as the front-end. If you are using the IRENA FlexTool web-interface, the instructions still apply, but the example figures in this tutorial will not be as helpful. IRENA FlexTool concepts are explained in more depth at this page . Video tutorial for Building a small test system can be watched here . The small system to be built is also directly available in the FlexTool repository ( Init SQLite database) and can be opened with the Spine Toolbox database editor. The default workflow for IRENA FlexTool executes the scenarios from the Input data database (and not from the Init SQLite database). The Input data database is empty by default. Therefore, if you want to use directly the contents of the Init database (instead of building the small system step-by-step), you need to copy them to the Input data database before running the scenarios in this tutorial. To copy the data, you need to execute the Initialize workflow item: select the item, press Execute selection from the toolbar. It is not advised to run the whole workflow, ( Execute project ) since it will copy data from two sources: the Excel based input data file and the Init database and this will create two sets of data in the Input data database. More information on how to set-up and use the Spine Toolbox front-end in here . Remark: in case you had already populated the Input data database, you need to delete the data before importing from Init SQLite database. This can be done with the 'purge' tool from the Database Editor menu: in purge , click on both Select entity and value items , and Select scenario items and then purge. Building a small test system 1st step - a node with no units 2nd step - add a coal unit 3rd step - add a wind power plant 4th step - add a network 5th step - add a reserve More functionality Adding a storage unit (battery) Adding battery investment capabilities Minimum load example Adding CO2 emissions and costs Full year model A system with coal, wind, network, battery and CO2 over a full year Representative periods Multi-year model Discount calculations Building a small test system This tutorial can be used in couple of different ways - the best way depends on your familiarity with energy system modelling. First, all users who are not familiar with the way FlexTool manages data using Spine Toolbox functionalities , should read the page on Spine Toolbox workflow and the section on Spine Toolbox data structures . If you are new to energy system modelling , it is probably best to try to build the test system yourself while following the tutorial. This will take time and you will have to look up many data items from the Init database, but it will also force you to learn the concepts. You can also copy-paste data from the Init database to the Input data database when writing the data becomes too tedious. Before you start, it can be a good idea to to check the Essential objects for defining a power/energy system from the beginning of the FlexTool reference page to get an initial understanding of the concepts that will then grow as you learn more. If you have already run the whole workflow, then the Input_data database will be populated and you will need to delete the data before starting to build from scratch. This can be done with the 'purge' tool from the Database Editor menu: in purge , click on both Select entity and value items , and Select scenario items and then purge. If you have experience in using other types of energy system models - or perhaps older versions of FlexTool - it can be sufficient to follow the tutorial while also browsing the Init database using the database editor. Finding the entity classes, entities, and parameter values in the actual database will assist in the learning process. The concept reference page can also be useful. Finally, if you are a really experienced modeller , it can be enough to check the reference section starting from Essential objects for defining a power/energy system . 1st step - a node with no units You should have the FlexTool project open in the Spine Toolbox. Then, open the Input data database by double-clicking it in the Spine Toolbox workflow. The test system is built using alternatives . Alternative is a subset of the system than one can include to a scenario that is optimized by Flextool. For example when adding a wind plant, all the objects and relationships related to only the wind plant should be under their own alternative, so that the wind plant can be included or excluded form the scenario seamlessly. Each step will add a new alternative , and the data it contains, on top of the previous ones. The first alternative will be called west to hold the data for the first node in the model. The alternative is added in the 'Alternative/Scenario tree' widget of the 'Spine Database Editor', see figure below. Next step is to add an object for the first node that will be called west . Right-click on the node object class in the object tree to select 'Add objects'. Use the dialog to add the west node and click ok. See the figures below. Later other objects will need to be added in the same manner - as well as relationships between objects. Then, add parameter data to the newly minted west node : west node represents the demand in a part of the system. First add an inflow parameter with negative values to indicate negative inflow, i.e. demand. The inflow timeseries are given as a map-type parameter where the first column contains the names of the timesteps and the second column contains the inflow parameter value for that timestep. This is tedious to do by hand, so you can also copy-paste this from the init database. There are no electricity generating units and the demand cannot be met by ordinary means. The model will therefore use the upward slack variable and accept the penalty_up cost associated with it. This represents the cost of not fulfilling the demand. Also downward penalty_down is defined although the model is not using it at this stage. Here values of 9000 and 8000 are used respectively. Penalties and slack variables are tools of linear optimization. They ensure that the problem is feasable at all timesteps even when the in-out-balance of the nodes is violated. If no real penalty values are known, one should just use large enough numbers, so that the system won't prefer penalty to energy production. In the results, you can see at which timesteps the penalties are used. The parameter has_balance is related to this and should be set to yes . It forces the node to have a balance on inflow and outflow. If the demand is not fulfilled, balance is forced by the slack variable that will \"create\" the energy with the penalty associated with it. The west node needs to have a parameter called is_active with value yes . This chooses the west node and all its parameters to be sent to the model. All parameters here should be part of the west alternative (column alternative_name) - they will be used whenever a scenario includes the west alternative . The model will also need parameters that define the model structure for time related issues. FlexTool time structure offers a lot of flexibility, but it is also bit complex to learn at first. At this stage not everything needs to be understood - the time structures will be explained in more detail later. First, make a new alternative called init to keep all the model structure related data separate from the data on physical objects. All parameter data that will be added next should go into the init alternative . Then, to get the model to run, you need to create the following objects and relationships: timeline object called y2020 with a map-type parameter timestep_duration that defines the timeline the time series data in the model will need to use. It contains, in the first column, the name of each timestep (e.g. t0001 or 2022-01-01-01 ) and, in the second column, the length of the timestep in hours (e.g. 1.0 ). The timestep names in the previously given inflow time series must match these timestep names - and any other timestep names in later time series. timeblockset object called 2day with a map-type parameter block_duration to define a time block using a timestep name to indicate where the timeblock starts and a number to define the duration of the timeblock in timesteps (e.g. t0001 and 48.0 ). The timeline is larger than the 48, but this way the solver uses only the first 48h. timeblockset 2day and timeline y2020 need to have timeblockset__timeline relationship 2day , y2020 . From the relationship tree right-click on the timeblockset__timeline relationship class to 'Add relationships...'. solve object called y2020_2day_dispatch with a map-type parameter period_timeblockSet to define the timeblockset to be used by each period (in this example: period p2020 in the first column of the map links to the timeblockset object 2day in the second column of the map) with an array-type parameter realized_periods to define the periods that are realised from the solve named by the object (in this example: first column of the array is the index number 1 and the second column contains the period to be realized in the results: p2020 ) with a parameter solve_mode , to be set to single_shot . Finally, the model object needs to be created. It must contain the sequence of solves. In this case flexTool model object contains just one solve y2020_2day_dispatch inside the array-type parameter. Be careful when choosing datatypes! Maps need to be maps not arrays. (In the future, an update is coming to toolbox to make this easier.) The new objects, relationships and parameters have now been staged. Even though it looks like they are in the database, they really are not - they need to be committed first. This can be done from the menu of the Database Editor (there is a commit command) or by pressing ctrl-enter . One should write an informative commit message about the changes that have been made. All commits, and the data they have affected, can be seen later from the history menu item. Interlude - creating a scenario and running the model Even though the model is very simple and will not do anything interesting, it can be executed. It is first necessary to create the scenario to be executed. Scenarios are created from alternatives in the Scenario tree widget of the Database Editor. In the figure below, a scenario called base is created that should contain alternatives west and init in order to have both a node and a model structure included in the model. The new scenario must also be committed , before it can be used. A new scenario should be added after each step in the tutorial process. Once the scenario has been committed to the database, it becomes available in the Spine Toolbox workflow. One can select scenarios to be executed from the arrow that leaves the Input data database. At this point, there will be only the base scenario available and should be selected. There is also a tool filter with FlexTool3 pre-selected. This selection needs to be present when running scenarios (it is used to filter the is_active entities into the scenario). Next, we want to run three tools: Export_to_CSV (that will make input files suitable for FlexTool), FlexTool3 (which is a Python script that calls the FlexTool model generator for each solve) and Import_results (which will take output files from FlexTool and drop their contents to the Results database with a particular alternative name). First, select the three tools (select with left click while ctrl is pressed or draw an area with ctrl pressed, see figure below). Then, press Execute selection from the menu bar. The three items should be executed and if all goes well, then green check marks appear on each of the tool once it has finished. You can explore the outputs of each item by selecting the item and looking at the Console widget window. If the Results database has an error: database not found. Go to the Flextool folder, make a copy of the Results_template.sqlite to the same folder and name it Results.sqlite . After this run the Import_results tool again. It is now possible to explore model results for the base scenario using either the Results database or the Excel file that can be exported by executing the To_Excel exporter tool. When doing that, no scenarios should be selected so that the tool will create one Excel file with data from all the alternatives that are in the results database (which will make more sense once there are more scenario results). The generated Excel file can be found by selecting the To_Excel tool and clicking on the folder icon on top-right of the Link properties widget window. 2nd step - add a coal unit In the second step, a coal unit is added. The first thing is to add a new alternative coal so that all new data added in this step will become part of the coal alternative . Then one needs to add the objects: unit coal_plant node coal_market commodity coal And relationships: unit__inputNode coal_plant, coal_market to indicate that the coal_plant is using inputs from the coal_market unit__outputNode coal_plant, west to indicate that the coal_plant will output electricity to the west node commodity__node coal, coal_market coal_plant needs the following parameters (all set for the coal alternative): efficiency (e.g. 0.4 for 40% efficiency) existing to indicate the existing capacity in the coal_plant (e.g. 500 MW) is_active set to yes to include the coal_plant in the model coal commodity needs just one parameter for price (e.g. 20 \u20ac/MWh of fuel) coal_market node needs to have is_active set to yes All these new parameters should be now part of the coal alternative . To see how the results change due to the coal power plant, make a new scenario coal that has the alternatives init , west and coal . Run the Export_to_CSV , FlexTool3 and Import_results to get the results to the Results database. If you start to get too many result alternatives in the Results database (e.g. if you happen to run the same scenario multiple times), you can delete old ones by removing the unwanted alternatives (right-click on the alternative ) and then committing the database. Interlude - visualizing the system in a graph In Spine Toolbox, it is possible to visualize your system in a graph, which will show all objects, and the relationships between them. To open this visualization mode, open the Input data database. In the top right corner, click on the menu. Select Graph in the View section. You may visualize all objects by selecting root in the Object tree , or choose specifically the objects you want to display by selecting them in the Object tree (maintain ctrl to select multiple objects). 3rd step - add a wind power plant Next, a wind power plant is added. Add a new alternative wind Add objects: unit wind_plant profile wind_profile since wind_plant does not require a commodity, but instead uses a profile to limit the generation to the available wind. Add relationships: unit__node__profile wind_plant, west, wind_profile unit__outputNode wind_plant, west wind_plant needs the following parameters (all set for the wind alternative): conversion_method to choose a method for the conversion process (in this case constant_efficiency ) efficiency for wind_plant should be set to 1 existing capacity can be set to 1000 MW is_active set to yes to include the wind_plant in the model wind_profile needs the the parameter profile with a map of values where each time step gets the maximum available capacity factor for that time step (see figure). Again, you can copy this from the init database. wind_plant, west, wind_profile relationship needs a parameter profile_method with the choice upper_limit selected. This means that the wind_plant must generate at or below its capacity factor. You can now create a new scenario wind , that has the alternatives init , west , coal and wind . Remember to commit , execute and have a look at the results (there should be no more penalty values used, since the coal and wind plant can together meet the demand in all hours). 4th step - add a network A network alternative introduces two new nodes ( east and north ) three new connections between nodes ( east_north , west_east and west_north ). The new nodes are kept simple: they have a is_active parameter set to yes they have a has_balance parameter set to yes (to force the node to maintain an energy balance) they have a constant negative inflow (i.e. demand) penalty values for violating their energy balance The three connections have the following parameters: they have a is_active parameter set to yes they have a existing parameter to indicate the existing interconnection capacity between the nodes they have a efficiency parameter (e.g. 0.9 for 90% efficiency). It is also necessary to create the relationships connection__node__node for east_north | east | north , west_north | west | north and west_east | west | east . The north node has the lowest upward penalty, so the model will prefer to use that whenever the coal and wind units cannot meet all the demand. Sometimes the existing capacity of the new connections will not be sufficient to carry all the needed power, since both generators are producing to the west node . Commit , execute and explore. 5th step - add a reserve Create a new alternative reserve. Reserve requirement is defined for a group of nodes as the reserve can be set to be dependent on the loads of the nodes (this tutorial uses a constant reserve). Therefore, the first step is to add a new group called electricity with west , east and north as its members using the group__node relationship class. Then, a new reserve category called primary is added to the reserve object class. Finally, if it does not exist yet, add a new object `UpDown', called up to define the reserve mode. A relationship between primary--up--electricity in the reserve__upDown__group class allows to define the reserve parameters reserve_method , reservation (i.e. the amount of reserve) and penalty_reserve (i.e. the penalty cost in case of lack of reserve). In this case the reserve requirement will be a constant 10MW even though the reserve_method is timeseries_only . The other alternative is dynamic reserves where the model calculates the reserve requirement from generation and loads according to user defined factors ( increase_reserve_ratio ). Parameters from the reserve__upDown__unit__node class should be used to define how different units can contribute to different reserves. Parameter max_share says how large share of the total capacity of the timestep (existing * efficiency (profile)) of the unit can contribute to this reserve category (e.g. coal_plant , in this example, has ramping restrictions and can only provide 1% of it's capacity to this upward primary reserve.) Meanwhile, parameter reliability affects what portion of the reserved capacity actually contributes to the reserve (e.g. in this contrived example, wind_plant* must have extra capacity of 20 MW to provide 10 MW of reserve). Create the scenario, commit , execute and explore how the reserve requirements affect the model results. More functionality Adding a storage unit (battery) init - west - wind - battery In the Init SQLite database, there is a scenario wind_battery - the wind_plant alone is not able to meet the load in all conditions, but the battery will help it to improve the situation. In FlexTool, only nodes can have storage. This means that existing capacity and all investment parameters for nodes refer to the amount of storage the node can have. In this example, a battery node is established to describe the storage properties of the battery (e.g. existing capacity and self_discharge_loss in each hour). Battery also needs charging and discharging capabilities. These could be presented either with a connection or by having a charging unit and a discharging unit . In here, we are using a connection called batter_inverter , since its easier to prevent simultaneous charging and discharging that way (although, in a linear model, this cannot be fully prevented since that requires an integer variable). Please note that the efficiency parameter of the connection applies to both directions, so the round-trip efficiency will be efficiency squared. The transfer_method can be used by all types of connections, but in this case it is best to choose regular , which tries to avoid simultaneous charging and discharing, but can still do it when the model needs to dissipate energy. exact method would prevent that, but it would require integer variables and make the storage computationally much more expensive. Model leakage will be reported in the results (forthcoming). Adding battery investment capabilities init - west - wind - battery - battery_invest To make the wind_battery scenario more interesting, an option to invest in battery and battery_inverter is added. It also demonstrates how FlexTool can have more complicated constraints that the user defines through data. First, the investment parameters need to be included both for the battery_inverter and battery objects: invest_method - the modeller needs to choose between only_invest , only_retire , invest_and_retire or not_allowed invest_cost - overnight investment cost new capacity [currency/kW] for the battery_inverter and [currency/kWh] for the battery . Other one can be left empty or zero, since they will be tied together in the next phase. Here we will assume a fixed relation between kW and kWh for this battery technology, but for example flow batteries could have separate investments for storage and charging capacities. invest_max_total - maximum investment (power [MW] or energy [MWh]) to the virtual capacity of a group of units or to the storage capacity of a group of nodes. This should not be empty or zero, since then the model cannot invest in the technology. interest_rate - an interest rate [e.g. 0.05 means 5%] for the technology that is sufficient to cover capital costs assuming that the economic lifetime equals the technical lifetime lifetime - technical lifetime of the technology to calculate investment annuity (together with interest rate) Second, a new constraint needs to be created that ties together the storage capacity of the battery and the charging/discharging capacity of the battery_inverter . A new constraint object battery_tie_kW_kWh is created and it is given parameters constant , is_active and sense . Constant could be left out, since it is zero, but is_active must be defined in order to include the constraint in the battery_invest alternative . The sense of the constraint must be equal to enforce the kw/kWh relation. Third, both battery_inverter and battery need a coefficient to tell the model how they relate to each other. The equation has the capacity variables on the left side of the equation and the constant on the right side. sum_i(`constraint_capacity_coefficient` * `invested_capacity`) = `constant` where i is any unit, connection or node that is part of the constraint When the constraint_capacity_coefficient for battery is set at 1 and for the battery_inverter at -8, then the equation will force battery_inverter capacity to be 8 times smaller than the battery capacity . The negative term can be seen to move to the right side of the equation, which yields: 1 x *battery* = 8 x *battery_inverter*, which can be true only if *battery_inverter* is 1/8 of *battery* constraint_capacity_coefficient is not a parameter with a single value, but a map type parameter (index: constraint name, value: coefficient). It allows the object to participate in multiple constraints. Finally, FlexTool can actually mix three different types of constraint coefficients: constraint_capacity_coefficient , constraint_state_coefficient and constraint_flow_coefficient allowing the user to create custom constraints between any types of objects in the model for the main variables in the model ( flow , state as well as invest and divest ). So, the equation above is in full form: + sum_i [constraint_capacity_coefficient(i) * invested_capacity] where i contains [node, unit, connection] belonging to the constraint + sum_j [constraint_flow_coefficient(j) * invested_capacity] where j contains [unit--node, connection--node] belonging to the constraint + sum_k [constraint_state_coefficient(k) * invested_capacity] where k contains [node] belonging to the constraint = constant Combined heat and power (CHP) example init - west - coal_chp - heat This CHP plant is an another example where the user defined constraint (see the last equation in the previous example) is used to achieve desired behaviour. In a backpressure CHP, heat and power outputs are fixed - increase one of them, and you must also increase the other. In an extraction CHP plant the relation is more complicated - there is an allowed operating area between heat and power. Both can be depicted in FlexTool, but here a backpressure example is given. An extraction plant would require two or more greater_than and/or lesser_than constraints to define an operating area. First, a new heat node is added and it is given the necessary parameters. Then the coal_chp unit is made with a high efficiency parameter, since CHP units convert fuel energy to power and heat at high overall rates. In FlexTool, efficiency is a property of the unit - it demarcates at what rate the sum of inputs is converted to the sum of outputs. However, without any additional constraints, the unit is free to choose in what proportion to use inputs and in which proportion to use outputs. In units with only one input and output, this freedom does not exist, but in here, the coal_chp needs to be constrained as otherwise the unit could produce electricity at 90% efficiency, which is not feasible. This is done by adding a new constraint coal_chp_fix where the heat and power co-efficients are fixed. You need to create the two relationships unit__outputNode , for coal_chp--heat and coal_chp--west . As can be seen in the bottom part of the figure below, the constraint_flow_coefficient parameter for the coal_chp--heat and coal_chp--west is set as a map value where the constraint name matches with the coal_chp_fix constraint object name. The values are set so that the constraint equation forces the heat output to be twice as large as the electricity output. Again, the negative value moves the other variable to the right side of the equality, creating this: 1 x *electricity* = 0.5 x *heat*, which is true only if *heat* is 2 x *electricity* Minimum load example init - west - coal - coal_min_load The next example is simpler. It adds a minimum load behavior to the coal_plant unit . Minimum load requires that the unit must have an online variable in addition to flow variables and therefore a startup_method needs to be defined and an optional startup_cost can be given. The options are no_startup , linear and binary . binary would require an integer variable so linear is chosen. However, this means that the unit can startup partially. The minimum online will still apply, but it is the minimum of the online capacity in any given moment ( flow >= min_load x capacity_online ). The online variable also allows to change the efficiency of the plant between the minimum and full loads. An unit with a part-load efficiency will obey the following equation: + sum_i[ input(i) * input_coefficient(i) ] = + sum_o[ output(o) * output_coefficient(o) ] * slope + online * section where slope = 1 / efficiency - section and section = 1 / efficiency - ( 1 / efficiency - 1 / efficiency_at_min_load) / ( 1 - efficiency_at_min_load ) By default, input_coefficient and output_coefficient are 1, but if there is a need to tweak their relative contributions, these coefficients allow to do so (e.g. a coal plant might have lower efficieny when using lignite than when using brown coal). Adding CO2 emissions and costs init - west - coal - co2 Carbon dioxide emissions are added to FlexTool by associating relevant commodities (e.g. coal ) with a co2_content parameter (CO2 content per MWh of energy contained in the fuel). To set a price for the CO2, the nodes that use those commodities will need to be linked to a group of nodes that set the co2_price (currency / CO2 ton). Therefore, in addition to what is visible in the figure below, a relationship co2_price--coal_market must be established so that the model knows to point the CO2_price to the commodity used from the coal_market node based on the co2_content of the coal commodity . Full year model init - west - fullYear So far the model has been using only two days to keep it fast to run. This example extends the model horizon to a full year. To do so, a new solve object y2020_fullYear_dispatch is added. Each solve object needs to know what periods it will contain and what periods it will realize (print out results). solve_mode does not do anything at present, but will be used when FlexTool can be set to do automatic rolling window optimization (at present, it needs to be set manually using multiple solves). The key difference here is that the period_timeblockSet parameter points the p2020 period to a timeblockSet definition that covers the full year instead of the two days used before. A system with coal, wind, network, battery and CO2 over a full year init - west - coal - wind - network - battery - co2 - fullYear This example shows a system where many of the previous examples have been put into one model and run for one year. The graph below shows the physical objects in the example. Representative periods init - west - wind - battery - battery_invest - 5weeks When using the model for investment decisions, the model can often become too large to solve. Representative periods can be used to take a sample of a full year that tries to depict the dynamics in a reasonable manner. In FlexTool, this is done with the block_duration parameter. It needs to contain the starting timestep and the duration of each period as shown in figure below. Multi-year model init - west - wind - coal - coal_invest - 5weeks - multi-year A multi-year model is constructed from multiple periods, each presenting one year. In the example case, each year is otherwise the same, but the demand is increasing in the west node . The inflow time series are scaled to match the value in annual_flow . The model is using the inflow_method scale_to_annual in order to achieve this (default is use_original that would not perform scaling). There should also be a discount_rate parameter set for the model object flexTool if something else than the model default of 5% (0.05 value) is to be used. A multi-year model could be solved at one go or by rolling through several solves where each solve has a foresight horizon and a realisation horizon as can be seen from the figure below. In this example, the model rolls through several solves and therefore, in the figure above, the model object flexTool has four values in the solves array. Each value respresents one solve and it's position in the sequence of solves. Next figure shows the values needed to define one solve (out of the four solves in the example). All of these need to be repeated for each solve in the model. years_represented parameter is used by the model to calculate the discounting factors for the periods in the model (often future years). It should state the number of years each period will be representing. For example, a period for 2025 could represent the years 2025-2029 if its years_represented is set to 5. Any investments would be take place at the start of 2025 and discounted to the beginning of 2025, but the operational costs would accrue from each year in 2025-2029 each with a different discounting factor (decreasing based on interest rate). invest_periods parameter says in which periods the model is allowed to make investments realized_periods parameter states the periods that will be realized in this solve (results output) period_timeblockset defines the set of representative 'periods' (timeblocks in FlexTool) to be used in each FlexTool period . Discount calculations Each asset that can be invested in should have invest_cost , lifetime and interest_rate parameters set and could have an optional fixed_cost . These are used to calculate the annuity of the investment. Annuity is used to annualize the investment cost, since FlexTool scales all costs (operational, investment and fixed) to annual level in order to make them comparable. Annuity is calculated as follows: invest_cost * interest_rate / { 1 - [ 1 / ( 1 + interest_rate ) ] ^ lifetime } + fixed_cost The next step is to consider discounting - future is valued less than the present. There is a model-wide assumption for the discount_rate . By default it is 0.05 (i.e. 5%), but it can be changed through the discount_rate parameter set for the flexTool model object. Discount factor for every period in the model is calculated from the discount_rate using the years_represented parameter of each solve , which how many years the period represents. Values for years_represented are used to calculate how many years_from_solve_start each year is. The formula is: [ 1 / ( 1 + discount_rate ) ] ^ years_from_solve_start Operational costs are also discounted using the same discount_rate . However, with operational costs it is assumed that they take place on average at the middle of the year whereas investment costs are assumed to take place at the beginning of the year (they are available for the whole year). These can be tweaked with the discount_offset_investments and discount_offset_operations parameters (given in years). Please note that given this formulation, invest_cost should be the overnight built cost (as is typical in energy system modelling, the model does not assume any construction time - the financing costs of the construction period need to be included in your cost assumptions). The model has a model horizon based on the years_represented parameters. The model will not include discounted investment annuities after the model horizon (in other words, the investments are 'returned' at the end of the model horizon). Naturally also operational costs are included only until the end of the model horizon. Finally, the retirements work similar to investments using the same discount_rate and interest_rate parameters but with salvage_value as the benefit from retiring the unit.","title":"Home"},{"location":"#irena-flextool-tutorial","text":"IRENA FlexTool is an energy systems optimisation model developed for power and energy systems with high shares of wind and solar power. It can be used to find cost-effective sources of flexibility across the energy system to mitigate the increasing variability arising from the power systems. It can perform multi-year capacity expansion as well as unit commitment and economic dispatch in a user-defined sequence of solves. The aim has been to make it fast to learn and easy to use while including lot of functionality especially in the time scales relevant for investment planning and operational scheduling of energy systems. The instructions for installing IRENA FlexTool are here . This user guide will build a small system step-by-step. It assumes you will be using Spine Toolbox as the front-end. If you are using the IRENA FlexTool web-interface, the instructions still apply, but the example figures in this tutorial will not be as helpful. IRENA FlexTool concepts are explained in more depth at this page . Video tutorial for Building a small test system can be watched here . The small system to be built is also directly available in the FlexTool repository ( Init SQLite database) and can be opened with the Spine Toolbox database editor. The default workflow for IRENA FlexTool executes the scenarios from the Input data database (and not from the Init SQLite database). The Input data database is empty by default. Therefore, if you want to use directly the contents of the Init database (instead of building the small system step-by-step), you need to copy them to the Input data database before running the scenarios in this tutorial. To copy the data, you need to execute the Initialize workflow item: select the item, press Execute selection from the toolbar. It is not advised to run the whole workflow, ( Execute project ) since it will copy data from two sources: the Excel based input data file and the Init database and this will create two sets of data in the Input data database. More information on how to set-up and use the Spine Toolbox front-end in here . Remark: in case you had already populated the Input data database, you need to delete the data before importing from Init SQLite database. This can be done with the 'purge' tool from the Database Editor menu: in purge , click on both Select entity and value items , and Select scenario items and then purge. Building a small test system 1st step - a node with no units 2nd step - add a coal unit 3rd step - add a wind power plant 4th step - add a network 5th step - add a reserve More functionality Adding a storage unit (battery) Adding battery investment capabilities Minimum load example Adding CO2 emissions and costs Full year model A system with coal, wind, network, battery and CO2 over a full year Representative periods Multi-year model Discount calculations","title":"IRENA FlexTool tutorial"},{"location":"#building-a-small-test-system","text":"This tutorial can be used in couple of different ways - the best way depends on your familiarity with energy system modelling. First, all users who are not familiar with the way FlexTool manages data using Spine Toolbox functionalities , should read the page on Spine Toolbox workflow and the section on Spine Toolbox data structures . If you are new to energy system modelling , it is probably best to try to build the test system yourself while following the tutorial. This will take time and you will have to look up many data items from the Init database, but it will also force you to learn the concepts. You can also copy-paste data from the Init database to the Input data database when writing the data becomes too tedious. Before you start, it can be a good idea to to check the Essential objects for defining a power/energy system from the beginning of the FlexTool reference page to get an initial understanding of the concepts that will then grow as you learn more. If you have already run the whole workflow, then the Input_data database will be populated and you will need to delete the data before starting to build from scratch. This can be done with the 'purge' tool from the Database Editor menu: in purge , click on both Select entity and value items , and Select scenario items and then purge. If you have experience in using other types of energy system models - or perhaps older versions of FlexTool - it can be sufficient to follow the tutorial while also browsing the Init database using the database editor. Finding the entity classes, entities, and parameter values in the actual database will assist in the learning process. The concept reference page can also be useful. Finally, if you are a really experienced modeller , it can be enough to check the reference section starting from Essential objects for defining a power/energy system .","title":"Building a small test system"},{"location":"#1st-step-a-node-with-no-units","text":"You should have the FlexTool project open in the Spine Toolbox. Then, open the Input data database by double-clicking it in the Spine Toolbox workflow. The test system is built using alternatives . Alternative is a subset of the system than one can include to a scenario that is optimized by Flextool. For example when adding a wind plant, all the objects and relationships related to only the wind plant should be under their own alternative, so that the wind plant can be included or excluded form the scenario seamlessly. Each step will add a new alternative , and the data it contains, on top of the previous ones. The first alternative will be called west to hold the data for the first node in the model. The alternative is added in the 'Alternative/Scenario tree' widget of the 'Spine Database Editor', see figure below. Next step is to add an object for the first node that will be called west . Right-click on the node object class in the object tree to select 'Add objects'. Use the dialog to add the west node and click ok. See the figures below. Later other objects will need to be added in the same manner - as well as relationships between objects. Then, add parameter data to the newly minted west node : west node represents the demand in a part of the system. First add an inflow parameter with negative values to indicate negative inflow, i.e. demand. The inflow timeseries are given as a map-type parameter where the first column contains the names of the timesteps and the second column contains the inflow parameter value for that timestep. This is tedious to do by hand, so you can also copy-paste this from the init database. There are no electricity generating units and the demand cannot be met by ordinary means. The model will therefore use the upward slack variable and accept the penalty_up cost associated with it. This represents the cost of not fulfilling the demand. Also downward penalty_down is defined although the model is not using it at this stage. Here values of 9000 and 8000 are used respectively. Penalties and slack variables are tools of linear optimization. They ensure that the problem is feasable at all timesteps even when the in-out-balance of the nodes is violated. If no real penalty values are known, one should just use large enough numbers, so that the system won't prefer penalty to energy production. In the results, you can see at which timesteps the penalties are used. The parameter has_balance is related to this and should be set to yes . It forces the node to have a balance on inflow and outflow. If the demand is not fulfilled, balance is forced by the slack variable that will \"create\" the energy with the penalty associated with it. The west node needs to have a parameter called is_active with value yes . This chooses the west node and all its parameters to be sent to the model. All parameters here should be part of the west alternative (column alternative_name) - they will be used whenever a scenario includes the west alternative . The model will also need parameters that define the model structure for time related issues. FlexTool time structure offers a lot of flexibility, but it is also bit complex to learn at first. At this stage not everything needs to be understood - the time structures will be explained in more detail later. First, make a new alternative called init to keep all the model structure related data separate from the data on physical objects. All parameter data that will be added next should go into the init alternative . Then, to get the model to run, you need to create the following objects and relationships: timeline object called y2020 with a map-type parameter timestep_duration that defines the timeline the time series data in the model will need to use. It contains, in the first column, the name of each timestep (e.g. t0001 or 2022-01-01-01 ) and, in the second column, the length of the timestep in hours (e.g. 1.0 ). The timestep names in the previously given inflow time series must match these timestep names - and any other timestep names in later time series. timeblockset object called 2day with a map-type parameter block_duration to define a time block using a timestep name to indicate where the timeblock starts and a number to define the duration of the timeblock in timesteps (e.g. t0001 and 48.0 ). The timeline is larger than the 48, but this way the solver uses only the first 48h. timeblockset 2day and timeline y2020 need to have timeblockset__timeline relationship 2day , y2020 . From the relationship tree right-click on the timeblockset__timeline relationship class to 'Add relationships...'. solve object called y2020_2day_dispatch with a map-type parameter period_timeblockSet to define the timeblockset to be used by each period (in this example: period p2020 in the first column of the map links to the timeblockset object 2day in the second column of the map) with an array-type parameter realized_periods to define the periods that are realised from the solve named by the object (in this example: first column of the array is the index number 1 and the second column contains the period to be realized in the results: p2020 ) with a parameter solve_mode , to be set to single_shot . Finally, the model object needs to be created. It must contain the sequence of solves. In this case flexTool model object contains just one solve y2020_2day_dispatch inside the array-type parameter. Be careful when choosing datatypes! Maps need to be maps not arrays. (In the future, an update is coming to toolbox to make this easier.) The new objects, relationships and parameters have now been staged. Even though it looks like they are in the database, they really are not - they need to be committed first. This can be done from the menu of the Database Editor (there is a commit command) or by pressing ctrl-enter . One should write an informative commit message about the changes that have been made. All commits, and the data they have affected, can be seen later from the history menu item.","title":"1st step - a node with no units"},{"location":"#interlude-creating-a-scenario-and-running-the-model","text":"Even though the model is very simple and will not do anything interesting, it can be executed. It is first necessary to create the scenario to be executed. Scenarios are created from alternatives in the Scenario tree widget of the Database Editor. In the figure below, a scenario called base is created that should contain alternatives west and init in order to have both a node and a model structure included in the model. The new scenario must also be committed , before it can be used. A new scenario should be added after each step in the tutorial process. Once the scenario has been committed to the database, it becomes available in the Spine Toolbox workflow. One can select scenarios to be executed from the arrow that leaves the Input data database. At this point, there will be only the base scenario available and should be selected. There is also a tool filter with FlexTool3 pre-selected. This selection needs to be present when running scenarios (it is used to filter the is_active entities into the scenario). Next, we want to run three tools: Export_to_CSV (that will make input files suitable for FlexTool), FlexTool3 (which is a Python script that calls the FlexTool model generator for each solve) and Import_results (which will take output files from FlexTool and drop their contents to the Results database with a particular alternative name). First, select the three tools (select with left click while ctrl is pressed or draw an area with ctrl pressed, see figure below). Then, press Execute selection from the menu bar. The three items should be executed and if all goes well, then green check marks appear on each of the tool once it has finished. You can explore the outputs of each item by selecting the item and looking at the Console widget window. If the Results database has an error: database not found. Go to the Flextool folder, make a copy of the Results_template.sqlite to the same folder and name it Results.sqlite . After this run the Import_results tool again. It is now possible to explore model results for the base scenario using either the Results database or the Excel file that can be exported by executing the To_Excel exporter tool. When doing that, no scenarios should be selected so that the tool will create one Excel file with data from all the alternatives that are in the results database (which will make more sense once there are more scenario results). The generated Excel file can be found by selecting the To_Excel tool and clicking on the folder icon on top-right of the Link properties widget window.","title":"Interlude - creating a scenario and running the model"},{"location":"#2nd-step-add-a-coal-unit","text":"In the second step, a coal unit is added. The first thing is to add a new alternative coal so that all new data added in this step will become part of the coal alternative . Then one needs to add the objects: unit coal_plant node coal_market commodity coal And relationships: unit__inputNode coal_plant, coal_market to indicate that the coal_plant is using inputs from the coal_market unit__outputNode coal_plant, west to indicate that the coal_plant will output electricity to the west node commodity__node coal, coal_market coal_plant needs the following parameters (all set for the coal alternative): efficiency (e.g. 0.4 for 40% efficiency) existing to indicate the existing capacity in the coal_plant (e.g. 500 MW) is_active set to yes to include the coal_plant in the model coal commodity needs just one parameter for price (e.g. 20 \u20ac/MWh of fuel) coal_market node needs to have is_active set to yes All these new parameters should be now part of the coal alternative . To see how the results change due to the coal power plant, make a new scenario coal that has the alternatives init , west and coal . Run the Export_to_CSV , FlexTool3 and Import_results to get the results to the Results database. If you start to get too many result alternatives in the Results database (e.g. if you happen to run the same scenario multiple times), you can delete old ones by removing the unwanted alternatives (right-click on the alternative ) and then committing the database.","title":"2nd step - add a coal unit"},{"location":"#interlude-visualizing-the-system-in-a-graph","text":"In Spine Toolbox, it is possible to visualize your system in a graph, which will show all objects, and the relationships between them. To open this visualization mode, open the Input data database. In the top right corner, click on the menu. Select Graph in the View section. You may visualize all objects by selecting root in the Object tree , or choose specifically the objects you want to display by selecting them in the Object tree (maintain ctrl to select multiple objects).","title":"Interlude - visualizing the system in a graph"},{"location":"#3rd-step-add-a-wind-power-plant","text":"Next, a wind power plant is added. Add a new alternative wind Add objects: unit wind_plant profile wind_profile since wind_plant does not require a commodity, but instead uses a profile to limit the generation to the available wind. Add relationships: unit__node__profile wind_plant, west, wind_profile unit__outputNode wind_plant, west wind_plant needs the following parameters (all set for the wind alternative): conversion_method to choose a method for the conversion process (in this case constant_efficiency ) efficiency for wind_plant should be set to 1 existing capacity can be set to 1000 MW is_active set to yes to include the wind_plant in the model wind_profile needs the the parameter profile with a map of values where each time step gets the maximum available capacity factor for that time step (see figure). Again, you can copy this from the init database. wind_plant, west, wind_profile relationship needs a parameter profile_method with the choice upper_limit selected. This means that the wind_plant must generate at or below its capacity factor. You can now create a new scenario wind , that has the alternatives init , west , coal and wind . Remember to commit , execute and have a look at the results (there should be no more penalty values used, since the coal and wind plant can together meet the demand in all hours).","title":"3rd step - add a wind power plant"},{"location":"#4th-step-add-a-network","text":"A network alternative introduces two new nodes ( east and north ) three new connections between nodes ( east_north , west_east and west_north ). The new nodes are kept simple: they have a is_active parameter set to yes they have a has_balance parameter set to yes (to force the node to maintain an energy balance) they have a constant negative inflow (i.e. demand) penalty values for violating their energy balance The three connections have the following parameters: they have a is_active parameter set to yes they have a existing parameter to indicate the existing interconnection capacity between the nodes they have a efficiency parameter (e.g. 0.9 for 90% efficiency). It is also necessary to create the relationships connection__node__node for east_north | east | north , west_north | west | north and west_east | west | east . The north node has the lowest upward penalty, so the model will prefer to use that whenever the coal and wind units cannot meet all the demand. Sometimes the existing capacity of the new connections will not be sufficient to carry all the needed power, since both generators are producing to the west node . Commit , execute and explore.","title":"4th step - add a network"},{"location":"#5th-step-add-a-reserve","text":"Create a new alternative reserve. Reserve requirement is defined for a group of nodes as the reserve can be set to be dependent on the loads of the nodes (this tutorial uses a constant reserve). Therefore, the first step is to add a new group called electricity with west , east and north as its members using the group__node relationship class. Then, a new reserve category called primary is added to the reserve object class. Finally, if it does not exist yet, add a new object `UpDown', called up to define the reserve mode. A relationship between primary--up--electricity in the reserve__upDown__group class allows to define the reserve parameters reserve_method , reservation (i.e. the amount of reserve) and penalty_reserve (i.e. the penalty cost in case of lack of reserve). In this case the reserve requirement will be a constant 10MW even though the reserve_method is timeseries_only . The other alternative is dynamic reserves where the model calculates the reserve requirement from generation and loads according to user defined factors ( increase_reserve_ratio ). Parameters from the reserve__upDown__unit__node class should be used to define how different units can contribute to different reserves. Parameter max_share says how large share of the total capacity of the timestep (existing * efficiency (profile)) of the unit can contribute to this reserve category (e.g. coal_plant , in this example, has ramping restrictions and can only provide 1% of it's capacity to this upward primary reserve.) Meanwhile, parameter reliability affects what portion of the reserved capacity actually contributes to the reserve (e.g. in this contrived example, wind_plant* must have extra capacity of 20 MW to provide 10 MW of reserve). Create the scenario, commit , execute and explore how the reserve requirements affect the model results.","title":"5th step - add a reserve"},{"location":"#more-functionality","text":"","title":"More functionality"},{"location":"#adding-a-storage-unit-battery","text":"init - west - wind - battery In the Init SQLite database, there is a scenario wind_battery - the wind_plant alone is not able to meet the load in all conditions, but the battery will help it to improve the situation. In FlexTool, only nodes can have storage. This means that existing capacity and all investment parameters for nodes refer to the amount of storage the node can have. In this example, a battery node is established to describe the storage properties of the battery (e.g. existing capacity and self_discharge_loss in each hour). Battery also needs charging and discharging capabilities. These could be presented either with a connection or by having a charging unit and a discharging unit . In here, we are using a connection called batter_inverter , since its easier to prevent simultaneous charging and discharging that way (although, in a linear model, this cannot be fully prevented since that requires an integer variable). Please note that the efficiency parameter of the connection applies to both directions, so the round-trip efficiency will be efficiency squared. The transfer_method can be used by all types of connections, but in this case it is best to choose regular , which tries to avoid simultaneous charging and discharing, but can still do it when the model needs to dissipate energy. exact method would prevent that, but it would require integer variables and make the storage computationally much more expensive. Model leakage will be reported in the results (forthcoming).","title":"Adding a storage unit (battery)"},{"location":"#adding-battery-investment-capabilities","text":"init - west - wind - battery - battery_invest To make the wind_battery scenario more interesting, an option to invest in battery and battery_inverter is added. It also demonstrates how FlexTool can have more complicated constraints that the user defines through data. First, the investment parameters need to be included both for the battery_inverter and battery objects: invest_method - the modeller needs to choose between only_invest , only_retire , invest_and_retire or not_allowed invest_cost - overnight investment cost new capacity [currency/kW] for the battery_inverter and [currency/kWh] for the battery . Other one can be left empty or zero, since they will be tied together in the next phase. Here we will assume a fixed relation between kW and kWh for this battery technology, but for example flow batteries could have separate investments for storage and charging capacities. invest_max_total - maximum investment (power [MW] or energy [MWh]) to the virtual capacity of a group of units or to the storage capacity of a group of nodes. This should not be empty or zero, since then the model cannot invest in the technology. interest_rate - an interest rate [e.g. 0.05 means 5%] for the technology that is sufficient to cover capital costs assuming that the economic lifetime equals the technical lifetime lifetime - technical lifetime of the technology to calculate investment annuity (together with interest rate) Second, a new constraint needs to be created that ties together the storage capacity of the battery and the charging/discharging capacity of the battery_inverter . A new constraint object battery_tie_kW_kWh is created and it is given parameters constant , is_active and sense . Constant could be left out, since it is zero, but is_active must be defined in order to include the constraint in the battery_invest alternative . The sense of the constraint must be equal to enforce the kw/kWh relation. Third, both battery_inverter and battery need a coefficient to tell the model how they relate to each other. The equation has the capacity variables on the left side of the equation and the constant on the right side. sum_i(`constraint_capacity_coefficient` * `invested_capacity`) = `constant` where i is any unit, connection or node that is part of the constraint When the constraint_capacity_coefficient for battery is set at 1 and for the battery_inverter at -8, then the equation will force battery_inverter capacity to be 8 times smaller than the battery capacity . The negative term can be seen to move to the right side of the equation, which yields: 1 x *battery* = 8 x *battery_inverter*, which can be true only if *battery_inverter* is 1/8 of *battery* constraint_capacity_coefficient is not a parameter with a single value, but a map type parameter (index: constraint name, value: coefficient). It allows the object to participate in multiple constraints. Finally, FlexTool can actually mix three different types of constraint coefficients: constraint_capacity_coefficient , constraint_state_coefficient and constraint_flow_coefficient allowing the user to create custom constraints between any types of objects in the model for the main variables in the model ( flow , state as well as invest and divest ). So, the equation above is in full form: + sum_i [constraint_capacity_coefficient(i) * invested_capacity] where i contains [node, unit, connection] belonging to the constraint + sum_j [constraint_flow_coefficient(j) * invested_capacity] where j contains [unit--node, connection--node] belonging to the constraint + sum_k [constraint_state_coefficient(k) * invested_capacity] where k contains [node] belonging to the constraint = constant","title":"Adding battery investment capabilities"},{"location":"#combined-heat-and-power-chp-example","text":"init - west - coal_chp - heat This CHP plant is an another example where the user defined constraint (see the last equation in the previous example) is used to achieve desired behaviour. In a backpressure CHP, heat and power outputs are fixed - increase one of them, and you must also increase the other. In an extraction CHP plant the relation is more complicated - there is an allowed operating area between heat and power. Both can be depicted in FlexTool, but here a backpressure example is given. An extraction plant would require two or more greater_than and/or lesser_than constraints to define an operating area. First, a new heat node is added and it is given the necessary parameters. Then the coal_chp unit is made with a high efficiency parameter, since CHP units convert fuel energy to power and heat at high overall rates. In FlexTool, efficiency is a property of the unit - it demarcates at what rate the sum of inputs is converted to the sum of outputs. However, without any additional constraints, the unit is free to choose in what proportion to use inputs and in which proportion to use outputs. In units with only one input and output, this freedom does not exist, but in here, the coal_chp needs to be constrained as otherwise the unit could produce electricity at 90% efficiency, which is not feasible. This is done by adding a new constraint coal_chp_fix where the heat and power co-efficients are fixed. You need to create the two relationships unit__outputNode , for coal_chp--heat and coal_chp--west . As can be seen in the bottom part of the figure below, the constraint_flow_coefficient parameter for the coal_chp--heat and coal_chp--west is set as a map value where the constraint name matches with the coal_chp_fix constraint object name. The values are set so that the constraint equation forces the heat output to be twice as large as the electricity output. Again, the negative value moves the other variable to the right side of the equality, creating this: 1 x *electricity* = 0.5 x *heat*, which is true only if *heat* is 2 x *electricity*","title":"Combined heat and power (CHP) example"},{"location":"#minimum-load-example","text":"init - west - coal - coal_min_load The next example is simpler. It adds a minimum load behavior to the coal_plant unit . Minimum load requires that the unit must have an online variable in addition to flow variables and therefore a startup_method needs to be defined and an optional startup_cost can be given. The options are no_startup , linear and binary . binary would require an integer variable so linear is chosen. However, this means that the unit can startup partially. The minimum online will still apply, but it is the minimum of the online capacity in any given moment ( flow >= min_load x capacity_online ). The online variable also allows to change the efficiency of the plant between the minimum and full loads. An unit with a part-load efficiency will obey the following equation: + sum_i[ input(i) * input_coefficient(i) ] = + sum_o[ output(o) * output_coefficient(o) ] * slope + online * section where slope = 1 / efficiency - section and section = 1 / efficiency - ( 1 / efficiency - 1 / efficiency_at_min_load) / ( 1 - efficiency_at_min_load ) By default, input_coefficient and output_coefficient are 1, but if there is a need to tweak their relative contributions, these coefficients allow to do so (e.g. a coal plant might have lower efficieny when using lignite than when using brown coal).","title":"Minimum load example"},{"location":"#adding-co2-emissions-and-costs","text":"init - west - coal - co2 Carbon dioxide emissions are added to FlexTool by associating relevant commodities (e.g. coal ) with a co2_content parameter (CO2 content per MWh of energy contained in the fuel). To set a price for the CO2, the nodes that use those commodities will need to be linked to a group of nodes that set the co2_price (currency / CO2 ton). Therefore, in addition to what is visible in the figure below, a relationship co2_price--coal_market must be established so that the model knows to point the CO2_price to the commodity used from the coal_market node based on the co2_content of the coal commodity .","title":"Adding CO2 emissions and costs"},{"location":"#full-year-model","text":"init - west - fullYear So far the model has been using only two days to keep it fast to run. This example extends the model horizon to a full year. To do so, a new solve object y2020_fullYear_dispatch is added. Each solve object needs to know what periods it will contain and what periods it will realize (print out results). solve_mode does not do anything at present, but will be used when FlexTool can be set to do automatic rolling window optimization (at present, it needs to be set manually using multiple solves). The key difference here is that the period_timeblockSet parameter points the p2020 period to a timeblockSet definition that covers the full year instead of the two days used before.","title":"Full year model"},{"location":"#a-system-with-coal-wind-network-battery-and-co2-over-a-full-year","text":"init - west - coal - wind - network - battery - co2 - fullYear This example shows a system where many of the previous examples have been put into one model and run for one year. The graph below shows the physical objects in the example.","title":"A system with coal, wind, network, battery and CO2 over a full year"},{"location":"#representative-periods","text":"init - west - wind - battery - battery_invest - 5weeks When using the model for investment decisions, the model can often become too large to solve. Representative periods can be used to take a sample of a full year that tries to depict the dynamics in a reasonable manner. In FlexTool, this is done with the block_duration parameter. It needs to contain the starting timestep and the duration of each period as shown in figure below.","title":"Representative periods"},{"location":"#multi-year-model","text":"init - west - wind - coal - coal_invest - 5weeks - multi-year A multi-year model is constructed from multiple periods, each presenting one year. In the example case, each year is otherwise the same, but the demand is increasing in the west node . The inflow time series are scaled to match the value in annual_flow . The model is using the inflow_method scale_to_annual in order to achieve this (default is use_original that would not perform scaling). There should also be a discount_rate parameter set for the model object flexTool if something else than the model default of 5% (0.05 value) is to be used. A multi-year model could be solved at one go or by rolling through several solves where each solve has a foresight horizon and a realisation horizon as can be seen from the figure below. In this example, the model rolls through several solves and therefore, in the figure above, the model object flexTool has four values in the solves array. Each value respresents one solve and it's position in the sequence of solves. Next figure shows the values needed to define one solve (out of the four solves in the example). All of these need to be repeated for each solve in the model. years_represented parameter is used by the model to calculate the discounting factors for the periods in the model (often future years). It should state the number of years each period will be representing. For example, a period for 2025 could represent the years 2025-2029 if its years_represented is set to 5. Any investments would be take place at the start of 2025 and discounted to the beginning of 2025, but the operational costs would accrue from each year in 2025-2029 each with a different discounting factor (decreasing based on interest rate). invest_periods parameter says in which periods the model is allowed to make investments realized_periods parameter states the periods that will be realized in this solve (results output) period_timeblockset defines the set of representative 'periods' (timeblocks in FlexTool) to be used in each FlexTool period .","title":"Multi-year model"},{"location":"#discount-calculations","text":"Each asset that can be invested in should have invest_cost , lifetime and interest_rate parameters set and could have an optional fixed_cost . These are used to calculate the annuity of the investment. Annuity is used to annualize the investment cost, since FlexTool scales all costs (operational, investment and fixed) to annual level in order to make them comparable. Annuity is calculated as follows: invest_cost * interest_rate / { 1 - [ 1 / ( 1 + interest_rate ) ] ^ lifetime } + fixed_cost The next step is to consider discounting - future is valued less than the present. There is a model-wide assumption for the discount_rate . By default it is 0.05 (i.e. 5%), but it can be changed through the discount_rate parameter set for the flexTool model object. Discount factor for every period in the model is calculated from the discount_rate using the years_represented parameter of each solve , which how many years the period represents. Values for years_represented are used to calculate how many years_from_solve_start each year is. The formula is: [ 1 / ( 1 + discount_rate ) ] ^ years_from_solve_start Operational costs are also discounted using the same discount_rate . However, with operational costs it is assumed that they take place on average at the middle of the year whereas investment costs are assumed to take place at the beginning of the year (they are available for the whole year). These can be tweaked with the discount_offset_investments and discount_offset_operations parameters (given in years). Please note that given this formulation, invest_cost should be the overnight built cost (as is typical in energy system modelling, the model does not assume any construction time - the financing costs of the construction period need to be included in your cost assumptions). The model has a model horizon based on the years_represented parameters. The model will not include discounted investment annuities after the model horizon (in other words, the investments are 'returned' at the end of the model horizon). Naturally also operational costs are included only until the end of the model horizon. Finally, the retirements work similar to investments using the same discount_rate and interest_rate parameters but with salvage_value as the benefit from retiring the unit.","title":"Discount calculations"},{"location":"browser_interface/","text":"Browser interface in brief The browser interface connects to an instance of FlexTool web interface . It can show and edit the same data as the Spine Toolbox. The workflow is not directly visible, but it is executed in the background when models are run. The main page shows the projects available for the user. The front page for the data editor shows all the data classes that can be shown and edited. Different data classes can be opened to separate browser tabs for convenience. Parameter data can be shown and edited once the user chooses an object and an alternative. On the 'Run' page, the user can select and execute scenarios. Finally, the results page shows the model outputs taken from the result database. The results database can also be opened with Spine Toolbox for more control over the shown data as well as export capabilities.","title":"Browser interface"},{"location":"browser_interface/#browser-interface-in-brief","text":"The browser interface connects to an instance of FlexTool web interface . It can show and edit the same data as the Spine Toolbox. The workflow is not directly visible, but it is executed in the background when models are run. The main page shows the projects available for the user. The front page for the data editor shows all the data classes that can be shown and edited. Different data classes can be opened to separate browser tabs for convenience. Parameter data can be shown and edited once the user chooses an object and an alternative. On the 'Run' page, the user can select and execute scenarios. Finally, the results page shows the model outputs taken from the result database. The results database can also be opened with Spine Toolbox for more control over the shown data as well as export capabilities.","title":"Browser interface in brief"},{"location":"how_to/","text":"Examples of creating parts of the system are added here in the future","title":"How to"},{"location":"install_toolbox/","text":"Installing Spine Toolbox and IRENA FlexTool on a local computer Follow video tutorial for installation here: https://youtu.be/N3qB0rzxPYw. Install Miniconda (or Anaconda) [Can be ignored if already installed] Start Anaconda prompt Create new Python environment [Also possible to use existing, up-to-date, Spine Toolbox environment] shell conda create -n flextool python=3.8 Activate the environment shell conda activate flextool Install Git to the environment [Also possible to use existing Git installation] shell conda install git cd to a directory into which both FlexTool and Spine Toolbox will make their own folders Clone the FlexTool Git repository shell git clone https://github.com/irena-flextool/flextool Install Spine Toolbox [Can be skipped if using existing Toolbox environment] Clone the Toolbox repository shell git clone https://github.com/Spine-project/Spine-Toolbox.git cd to the freshly created folder shell cd Spine-Toolbox Make sure Pip is up-to-date shell python -m pip install --upgrade pip Install packages required by Toolbox shell python -m pip install -r requirements.txt Launch Spine Toolbox shell python -m spinetoolbox Open FlexTool3 project in Spine Toolbox (Choose the flextool folder from File > Open project dialog) In case of problems when installing Spine Toolbox, more instructions are available at: https://github.com/Spine-project/Spine-Toolbox#installation Run Open a conda prompt. Activate the environment shell conda activate flextool Launch Spine Toolbox shell python -m spinetoolbox Open FlexTool3 project in Spine Toolbox (Choose the flextool folder from File > Open project dialog) In the flextool folder, make a copy the Results_template.sqlite and rename it Results.sqlite (Results.sqlite is not part of the repository to avoid accidental overwrites of your results in the future) Updating IRENA FlexTool Update of IRENA FlexTool to the latest version is done as follows - Start anaconda prompt - conda activate flextool (or whatever is your conda environment name for IRENA FlexTool) - cd to the FlexTool directory - git restore . (THIS WILL DELETE YOUR LOCAL CHANGES TO THE FILES IN THE WORKFLOW. This will be improved in the future. Currently you can work around this by making your own input files (Excel or SQLite) and pointing the workflow items (Excel_input_data or Input_Data) to your own files instead of the input_data.sqlite or FlexTool_import_template.xlsx.) - git pull","title":"Installing IRENA FlexTool - SpineToolbox"},{"location":"install_toolbox/#installing-spine-toolbox-and-irena-flextool-on-a-local-computer","text":"Follow video tutorial for installation here: https://youtu.be/N3qB0rzxPYw. Install Miniconda (or Anaconda) [Can be ignored if already installed] Start Anaconda prompt Create new Python environment [Also possible to use existing, up-to-date, Spine Toolbox environment] shell conda create -n flextool python=3.8 Activate the environment shell conda activate flextool Install Git to the environment [Also possible to use existing Git installation] shell conda install git cd to a directory into which both FlexTool and Spine Toolbox will make their own folders Clone the FlexTool Git repository shell git clone https://github.com/irena-flextool/flextool Install Spine Toolbox [Can be skipped if using existing Toolbox environment] Clone the Toolbox repository shell git clone https://github.com/Spine-project/Spine-Toolbox.git cd to the freshly created folder shell cd Spine-Toolbox Make sure Pip is up-to-date shell python -m pip install --upgrade pip Install packages required by Toolbox shell python -m pip install -r requirements.txt Launch Spine Toolbox shell python -m spinetoolbox Open FlexTool3 project in Spine Toolbox (Choose the flextool folder from File > Open project dialog) In case of problems when installing Spine Toolbox, more instructions are available at: https://github.com/Spine-project/Spine-Toolbox#installation","title":"Installing Spine Toolbox and IRENA FlexTool on a local computer"},{"location":"install_toolbox/#run","text":"Open a conda prompt. Activate the environment shell conda activate flextool Launch Spine Toolbox shell python -m spinetoolbox Open FlexTool3 project in Spine Toolbox (Choose the flextool folder from File > Open project dialog) In the flextool folder, make a copy the Results_template.sqlite and rename it Results.sqlite (Results.sqlite is not part of the repository to avoid accidental overwrites of your results in the future)","title":"Run"},{"location":"install_toolbox/#updating-irena-flextool","text":"Update of IRENA FlexTool to the latest version is done as follows - Start anaconda prompt - conda activate flextool (or whatever is your conda environment name for IRENA FlexTool) - cd to the FlexTool directory - git restore . (THIS WILL DELETE YOUR LOCAL CHANGES TO THE FILES IN THE WORKFLOW. This will be improved in the future. Currently you can work around this by making your own input files (Excel or SQLite) and pointing the workflow items (Excel_input_data or Input_Data) to your own files instead of the input_data.sqlite or FlexTool_import_template.xlsx.) - git pull","title":"Updating IRENA FlexTool"},{"location":"install_web_interface/","text":"Connecting to IRENA FlexTool server Instruction will be added later. The browser interface is shown Browser interface .","title":"Installing IRENA FlexTool - Web interface"},{"location":"install_web_interface/#connecting-to-irena-flextool-server","text":"Instruction will be added later. The browser interface is shown Browser interface .","title":"Connecting to IRENA FlexTool server"},{"location":"interface_overview/","text":"Main alternatives to use IRENA FlexTool Use a browser : IRENA FlexTool can be accessed with a web browser if you have an account for an IRENA FlexTool server. However, no public servers available at the moment. The browser interface is shown Browser interface . Local server: It is possible to setup a local server and then use a browser to access that server. See https://github.com/irena-flextool/flextool-web-interface Install a front-end : Install Spine Toolbox and run IRENA FlexTool as a Spine Toolbox project. This gives you the graphical user interface of Spine Toolbox. https://github.com/Spine-project/Spine-Toolbox. The interface and instructions to it are shown Toolbox interface","title":"Overview of the interfaces to Flextool"},{"location":"interface_overview/#main-alternatives-to-use-irena-flextool","text":"Use a browser : IRENA FlexTool can be accessed with a web browser if you have an account for an IRENA FlexTool server. However, no public servers available at the moment. The browser interface is shown Browser interface . Local server: It is possible to setup a local server and then use a browser to access that server. See https://github.com/irena-flextool/flextool-web-interface Install a front-end : Install Spine Toolbox and run IRENA FlexTool as a Spine Toolbox project. This gives you the graphical user interface of Spine Toolbox. https://github.com/Spine-project/Spine-Toolbox. The interface and instructions to it are shown Toolbox interface","title":"Main alternatives to use IRENA FlexTool"},{"location":"introduction/","text":"IRENA FlexTool IRENA FlexTool is an energy systems optimisation model developed for power and energy systems with high shares of wind and solar power. It can be used to find cost-effective sources of flexibility across the energy system to mitigate the increasing variability arising from the power systems. It can perform multi-year capacity expansion as well as unit commitment and economic dispatch in a user-defined sequence of solves. The aim has been to make it fast to learn and easy to use while including lot of functionality especially in the time scales relevant for investment planning and operational scheduling of energy systems. Documentation structure You can find the installation instructions for the interfaces Interface Overview Follow video tutorial for installation here: https://youtu.be/N3qB0rzxPYw. If using FlexTool with Spine Toolbox, learn how the Spine Toolbox workflow functions: Spine Toolbox workflow . If using FlexTool with a web-browser, read how it works: Browser interface . The tutorial is recommended for the new users of FlexTool: [Tutorial] (https://irena-flextool.github.io/flextool/tutorial) Finally, go to the documentation of the model parameters: Model parameters And results Model results","title":"Introduction"},{"location":"introduction/#irena-flextool","text":"IRENA FlexTool is an energy systems optimisation model developed for power and energy systems with high shares of wind and solar power. It can be used to find cost-effective sources of flexibility across the energy system to mitigate the increasing variability arising from the power systems. It can perform multi-year capacity expansion as well as unit commitment and economic dispatch in a user-defined sequence of solves. The aim has been to make it fast to learn and easy to use while including lot of functionality especially in the time scales relevant for investment planning and operational scheduling of energy systems.","title":"IRENA FlexTool"},{"location":"introduction/#documentation-structure","text":"You can find the installation instructions for the interfaces Interface Overview Follow video tutorial for installation here: https://youtu.be/N3qB0rzxPYw. If using FlexTool with Spine Toolbox, learn how the Spine Toolbox workflow functions: Spine Toolbox workflow . If using FlexTool with a web-browser, read how it works: Browser interface . The tutorial is recommended for the new users of FlexTool: [Tutorial] (https://irena-flextool.github.io/flextool/tutorial) Finally, go to the documentation of the model parameters: Model parameters And results Model results","title":"Documentation structure"},{"location":"reference/","text":"Main entities to define a power/energy system Elemental entities (one dimensional): node : maintain a balance between generation, consumption, transfers and storage state changes (nodes can also represent storages) unit : power plants or other conversion devices that take one or more inputs and turn them into one or more outputs connection : transmission lines or other transfer connections between nodes commodity : fuels or other commodities that are either purchased or sold at a price outside of the model scope profile : timeseries that can be used to constraint the behaviour of units, connections or storages reserve : reserve categories to withhold capacity to cope with issues outside of model scope Entities with two or more dimensions: unit__inputNode and unit__outputNode : defines the inputs, outputs and their properties for the conversion units connection__node__node : defines which nodes a connection will connect unit__node__profile and connection__profile : defines a profile limit (upper, lower or fixed) for an energy flow node__profile : defines a profile limit (upper, lower, or fixed) for the storage state of the node commodity__node : defines if a node is a source or sink for a commodity reserve__upDown__unit__node and reserve__upDown__connection__node : reserve capacity from a source to the target node See below for more detailed explanations. How to define the temporal properties of the model Timesteps and periods FlexTool has two different kinds of time varying parameters. The first one represents a regular timeline based on timesteps. The duration of each timestep can be defined by the user. There can be multiple timelines in the database - the user needs to define which timeline to use (and what parts of the timeline should be used, as will be explained later). The timestep names in the timeline are defined by the user - they can be abstract like 't0001' or follow a datetime format of choice. However, the timestep names between different timelines must remain unique (usually there should be only one timeline in a database and therefore no issues). The second time varying dimension is period , which is typically used to depict assumptions about the future. One model can include multiple solves that the model will solve in sequence (to allow multi-stage modelling). Each solve can include multiple periods (so that the user can change parameter values for different parts of the future). A parameter of particular type can be either constant/time-varying or constant/period-based. For example inflow is either a constant or time-varying, but it cannot be period-based. Timeblocksets Timeblocks pick one or more sections from the timeline to form a timeblockset . Each timeblock defines a start and a duration. The aim of timeblocksets is to allow the modeller to create models with representative periods often used in the investment planning. Definitions model : model defines the sequence of solves to be performed (e.g. first an investment solve and then a dispatch solve) solves : sequence of solves in the model represented with an array of solve names. discount_offset_investment : [years] Offset from the period (often year) start to the first payment of the investment cost annuity. discount_offset_operations : [years] Offset from the period (often year) start to the payment of operational costs. solve : each solve is built from an array of periods (e.g. one period for 2025 and another for 2030). Periods use timeblocksets to connect with a timeline. period_timeblockset : map of periods with associated timeblocks that will be included in the solve. Index: period name, value: timeblockSet name. realized_periods : these are the periods the model will 'realize' - i.e., what periods will be reported in the results from this solve invest_periods : array of periods where investements are allowed in this solve (applies only to objects that can be invested in) years_represented : Map to indicate how many years the period represents before the next period in the solve. Used for discounting. Can be below one (multiple periods in one year). Index: period, value: years. solver : choice of a solver (a list of possible values) highs_method : HiGHS solver method ('simplex' or 'ipm' which is interior point method). Should use 'choose' for MIP models, since 'simplex' and 'ipm' will not work. highs_parallel : HiGHS parallelises single solves or not ('on' or 'off'). It can be better to turn HiGHS parallel off when executing multiple scnearios in parallel. highs_presolve : HiGHS uses presolve ('on') or not ('off'). Can have a large impact on solution time when solves are large. solve_mode : a single shot or a set of rolling optimisation windows solved in a sequence (not functional yet, always a single shot). timeblockset : timeblocksets are sets of timeblocks with a start (from timeline) and a duration (number of time steps) block_duration a map with index timestep_name that starts the timeblock and value that defines the duration of the block (how many timesteps) timeline : continuous timeline with a user-defined duration for each timestep. Timelines are used by time series data. timestep_duration : a map with timestep_name as an index and duration as a value. timeline_duration_in_years Total duration of the timeline in years. Used to relate operational part of the model with the annualized part of the model. timeblockset__timeline : defines which timeline object particular timeblockset is using. Nodes Defining how the node functions These parameters will define how the node will behave and use the data it is given (available choices are marked in italics ): 'name' - unique name identifier (case sensitive) 'is_active' - is the model/node/unit active in a specific scenario: yes (if not defined, then not active) 'has_balance' - does the node maintain a balance for inputs and outputs: yes (if not defined, then balance is not maintained) 'has_storage' - does the node represent a storage and therefore have a state: yes (if not defined, then no storage) 'invest_method' - Choice of investment method: either not_allowed or then a combination of invest and/or retire investment limits for each period and/or for all periods ( total ) or no_limit 'inflow_method' - choice how to treat inflow time series use_original - does not scale the original time series (no value defaults here) no_inflow - ignores any inserted inflow time series scale_to_annual_flow - will scale the time series to match the annual_flow so that the sum of inflow is multiplied by 8760/ hours_in_solve scale_in_proprotion - calculates a scaling factor by dividing annual_flow with the sum of time series inflow (after it has been annualized using timeline_duration_in_years ) scale_to_annual_and_peak_flow - scales the time series to match the 'annual_flow' target while transforming the time series to match the highest load with the 'peak_inflow' Data for nodes Input data is set with the following parameters: 'inflow' - [MWh] Inflow into the node (negative is outflow). Constant or time series. 'annual_flow' - [MWh] Annual flow in energy units (always positive, the sign of inflow defines in/out). Constant or period. 'existing' - [MWh] Existing storage capacity (requires has_storage ). Constant. 'invest_cost' - [CUR/kWh] Investment cost for new storage capacity. Constant or period. 'salvage_value' - [CUR/kWh] Salvage value of the storage. Constant or period. 'lifetime' - [years] Life time of the storage unit represented by the node. Constant or period. 'interest_rate' - [unitless, e.g. 0.05 means 5%] Interest rate for investments. Constant or period. 'invest_max_total' - [MWh] Maximum storage investment over all solves. Constant. 'invest_max_period' - [MWh] Maximum storage investment for each period. Period. 'invest_min_total' - [MWh] Minimum storage investment over all solves. Constant. 'invest_min_period' - [MWh] Minimum storage investment for each period. Period. 'invest_forced' - [MWh] Storage capacity that must be invested in a given period. Investment cost will be included in the cost results even though the model does not have an investment variable. Constant or period. 'fixed_cost' - [CUR/kW] Annual fixed cost for storage. Constant or period. 'penalty_up' - [CUR/MWh] Penalty cost for decreasing consumption in the node with a slack variable. Constant or time. 'penalty_down' - [CUR/MWh] Penalty cost for increasing consumption in the node with a slack variable. Constant or time. 'virtual_unitsize' - [MWh] Size of a single storage unit - used for integer investments (lumped investments). If not given, assumed from the existing storage capacity. Using nodes as storages FlexTool manages storages through nodes. A regular node maintains an energy/material balance between all inputs and outputs ( has_balance set to yes ). A storage node includes an additional state variable, which means that the node can also use charging and discharging of the storage while maintaining the energy balance. A storage node is created by setting has_storage to yes and by adding storage capacity using the existing parameter and/or by letting the model invest in storage capacity ( invest_method , invest_cost , invest_max_period , invest_max_total and invest_forced parameters). Since FlexTool allows different temporal structures (multi-periods, rolling optimization, etc.) there needs to be ways to define how the storages behave when the model timeline is not fully consequtive. By default, storages are forced to match start level to the end level within timeblocks. This is an acceptable setting for small storages that do not carry meaningful amounts of energy between longer time periods in the model. There are three methods associated with storage start and end values: storage_binding_method , storage_start_end_method and storage_solve_horizon_method . The most simple one of these is the storage_start_end_method and it overrides the other methods, since it forces the start and/or the end state of the storage to a predefined value based on the proportional parameters storage_state_start and storage_state_end (proportional means that the parameter needs to be set between 0-1 and will be scaled by the storage capacity in the model). These two parameters affect only the first and the last timesteps of the entire model (even when the model has more than one solve). storage_binding_method states how the storage should behave over discontinuities in the model timeline. Model timeline can have jumps for three different reasons: timeblocks, periods, and solves. If storage_binding_method is bind_within_timeblock , then the storage has to match the state of the storage between the beginning and the end of each timeblock. In effect, storage_state_at_start_of_timeblock equals storage_state_at_end_of_timeblock plus charging minus discharging minus self_discharge_loss at the last timestep. Similarly, bind_within_period will force the start and end between periods, but it will treat the jumps between timeblocks as continuous from the storage perspective (the storage will continue from where it was at the end of the previous timeblock). bind_within_solve does effectively the same when there are multiple periods within one solve. bind_within_model (NOT IMPLEMENTED 19.3.2023) will extend the continuity to multiple solves and force the end state of the storage at the end of the last solve to match the beginning state of the storage at the start of the first solve. Finally, bind_forward_only will force continuity in the storage state over the whole model without forcing the end state to match the beginning state. storage_solve_horizon_method is meant for models that roll forward between solves and have an overlapping temporal window between those solves (e.g. a model with 36 hour horizon rolls forward 24 hours at each solve - those 12 last hours will be overwritten by the next solve). In these cases, the end state of the storage will be replaced by the next solve, but it can be valuable to have some guidance for the end level of storage, since it will affect storage behaviour. There are three methods: free is the default and will simply let the model choose where the storage state ends (usually the storage will be emptied, since it would have no monetary value). use_reference_value will use the value set by storage_state_reference_value to force the end state in each solve to match the reference value. use_reference_price will give monetary value for the storage content at the end of the solve horizon set by the storage_state_reference_price parameter - the model is free to choose how much it stores at the end of horizon based on this monetary value. -Method hierarchy: storage_start_end_method storage_binding_method storage_solve_horizon_method Meaning: The storage_binding_method is ignored (exeption bind_forward_only ), if storage_start_end_method has the value fix_start_end , The storage_solve_horizon_method use_reference_value is ignored, if other storage state methods are used. Only exeptions are fix_start or bind_forward_only Units Units convert energy (or matter) from one form to another (e.g. open cycle gas turbine), but the can also have multiple inputs and/or outputs (e.g. combined heat and power plant). The input nodes are defined with the relationship unit--inputNode while the output nodes are defined through the relationship unit--outputNode . Defining how the unit functions is_active to state the alternative where the unit becomes active 'conversion_method' to define the way unit converts inputs to outputs startup_method - Choice of startup method. 'Linear' startup means that the unit can start partially (anything between 0 and full capacity) but will face startup cost as well as minimum load limit based on the capacity started up. 'Binary' startup means that the unit is either off or fully on, but it is computationally more demanding than linearized startups. minimum_time_method - Not functional yet. Choice between minimum up- and downtimes ( , min_downtime , min_uptime , both ). Main data items for units Capacity: existing (and the investment and retirement parameters below) Technical: efficiency , min_load , efficiency_at_min_load , min_uptime , min_downtime min_load - [0-1] Minimum load of the unit. Applies only if the unit has an online variable. With linear startups, it is the share of capacity started up. Constant or time. Economic: startup_cost , fixed_cost (fuel cost comes through the use of fuel commodities and other variable costs are defined for flows between unit and node, see below) Investment parameters (for capacity expansion) investment/retirement method invest_cost , interest_rate , lifetime , invest_max_total , invest_max_period , invest_min_total , invest_min_period , invest_forced salvage_value , retire_max_total , retire_max_period , retire_min_total , retire_min_period , retire_forced Relationship of a unit to a node and determination of the type of relationship If the unit\u2019s outputs are flowing into the node, the node acts as output for the unit. If the unit\u2019s inputs are flowing out of the node (into the unit), the node acts as input for the unit. Not all units necessary have both an input and an output node. E.g. VRE generators have only output nodes and their generation is driven by profiles Properties of unit--inputNode and unit--outputNode relationships is_non_synchronous - Chooses whether the unit is synchronously connected to this node. coefficient - [factor] Coefficient to scale the output from a unit to a particular node. Can be used e.g. to change unit of measurement or to remove the flow by using zero as the coefficient (the flow variable can still be used in user constraints). Constant. other_operational_cost - [CUR/MWh] Other operational variable costs for energy flows. Constant or time. inertia_constant - [MWs/MW] Inertia constant for a synchronously connected unit to this node. Constant. ramp_method - Choice of ramp method. 'ramp_limit' poses a limit on the speed of ramp. 'ramp_cost' poses a cost on ramping the flow (NOT FUNCTIONAL AS OF 19.3.2023). ramp_cost - [CUR/MW] Cost of ramping the unit. Constant. ramp_speed_up - [per unit / minute] Maximum ramp up speed. Constant. ramp_speed_down - [per unit / minute] Maximum ramp down speed. Constant. Units constrained by profiles Some generators (e.g. VRE) are not converting energy from one node to the other. Instead, their generation is determined (or limited) by a specific generation profile set by a profile object with a profile_method , thats state whether the profile forces an upper_limit , lower_limit or equal ity. Finally profile object is given a profile time series (or it can also be a constant). One needs to use node__profile , unit__node__profile or connection__profile to apply the profile to specific energy flow (or storage state in the case of node__profile ). Connections Connections can have an existing transfer capacity as well as an opportunity to invest in new capacity and retire old capacity. The functional choices of connections include the is_active , transfer_method , invest_method , startup_method as well as a choice if the tranfer connection is_DC . Parameters for the connection are defined in the connection object, but the two nodes it connects are defined by establishing a relationship between connection--leftNode--rightNode . existing - [MW] Existing capacity. Constant. efficiency - [factor, typically between 0-1] Efficiency of a connection. Constant or time. constraint_capacity_coefficient - A map of coefficients (Index: constraint name, value: coefficient) to represent the participation of the connection capacity in user-defined constraints. [(invest - divest variable) x coefficient] will be added to the left side of the constraint equation. Invest and divest variables are not multiplied by unitsize. other_operational_cost - [CUR/MWh] Other operational variable cost for trasferring over the connection. Constant or time. fixed_cost - [CUR/kW] Annual fixed cost. Constant or period. invest_cost - [CUR/kW] Investment cost for new 'virtual' capacity. Constant or period. interest_rate - [e.g. 0.05 equals 5%] Interest rate for investments. Constant or period. lifetime - [years] Used to calculate annuity together with interest rate. Constant or period. other investment parameters: invest_max_total , invest_max_period , invest_min_total , invest_min_period , invest_forced , salvage_value is_DC - A flag whether the connection is DC (the flow will not be counted as synchronous if there is a non_synchronous_limit ). Default false. virtual_unitsize - [MW] Size of single connection - used for integer (lumped) investments. Commodities Some nodes can act as a source or a sink of commodities instead of forcing a balance between inputs and outputs. To make that happen, commodities must have a price and be connected to those nodes that serve (or buy) that particular commodity at the given price . In other words, commodity is separate from node so that the user can use the same commodity properties for multiple nodes. Commodities can also have a co2_content . The commodity and its nodes are connected by establishin a new relationship between the commodity and each of its nodes (e.g. coal--coal_market ). price - [CUR/MWh or other unit] Price of the commodity. Constant or period. co2_content - [CO2 ton per MWh] Constant. Groups Groups are used to make constraints that apply to a group of nodes, units and/or connections. A group is defined by creating a group object and then creating a relationship between the group and its members. The membership relationship classes are group__node , group__unit , group__connection , group__unit__node , group__connection__node and reserve__upDown__group . The choice of group members depends on what the group is trying to achieve. For instance a group that limits investments could have a set of units included in the group. Capacity limits for nodes, units and connections invest_method - the choice of method how to limit or force investments in capacity [MW or MWh] of the group members invest_max_total - [MW or MWh] Maximum investment to the virtual capacity of a group of units or to the storage capacity of a group of nodes. Total over all solves. invest_max_period - [MW or MWh] Maximum investment per period to the virtual capacity of a group of units or to the storage capacity of a group of nodes. invest_min_total - [MW or MWh] Minimum investment to the virtual capacity of a group of units or to the storage capacity of a group of nodes. Total over all solves. invest_min_period - [MW or MWh] Minimum investment per period to the virtual capacity of a group of units or to the storage capacity of a group of nodes. Cumulative and instant flow limits for unit__node s and connection__node s max_cumulative_flow - [MW] Limits the maximum cumulative flow for a group of connection_nodes and/or unit_nodes. It needs to be expressed as average flow, since the limit is multiplied by the model duration to get the cumulative limit (e.g. by 8760 if a single year is modelled). Applied for each solve. Constant or period. min_cumulative_flow - [MW] Limits the minimum cumulative flow for a group of connection_nodes and/or unit_nodes. It needs to be expressed as average flow, since the limit is multiplied by the model duration to get the cumulative limit (e.g. by 8760 if a single year is modelled). Applied for each solve. Constant or period. max_instant_flow - [MW] Maximum instantenous flow for the aggregated flow of all group members. Constant or period. min_instant_flow - [MW] Minimum instantenous flow for the aggregated flow of all group members. Constant or period. Limits for nodes has_inertia - A flag whether the group of nodes has an inertia constraint active. inertia_limit - [MWs] Minimum for synchronous inertia in the group of nodes. Constant or period. penalty_inertia - [CUR/MWs] Penalty for violating the inertia constraint. Constant or period. has_non_synchronous - A flag whether the group of nodes has the non-synchronous share constraint active. non_synchronous_limit - [share, e.g. 0.8 means 80%] The maximum share of non-synchronous generation in the node group. Constant or period. penalty_non_synchronous - [CUR/MWh] Penalty for violating the non synchronous constraint. Constant or period. has_capacity_margin - A flag whether the group of nodes has a capacity margin constraint in the investment mode. capacity_margin - [MW] How much capacity a node group is required to have in addition to the peak net load in the investment time series. Used only by the investment mode. Constant or period. penalty_capacity_margin - [CUR/MWh] Penalty for violating the capacity margin constraint. Constant or period. CO2 costs and limits co2_method - Choice of the CO2 method or a combination of methods: no_method, price, period, total, price_period, price_total, period_total, price_period_total. co2_price [CUR/ton] CO2 price for a group of nodes. Constant or period. co2_max_period [tCO2] Maximum limit for emitted CO2 in each period. co2_max_total [tCO2] Maximum limit for emitted CO2 in the whole solve. Controlling outputs Some results are output for groups of nodes. This means that instead of getting output for each node separately, nodes can be grouped and the aggregated results can be examined. For example all electricity nodes could be groupped for aggragated output. output_results - A flag to output aggregated results for the group members. Reserves The user defines reserve categories through reserve object. Reserves are reservations of capacity (either upward or downward) and that capacity will not therefore be available for other use (flowing energy or commodities). There are three different ways how a reserve requirement can be calculated: timeseries, large_failure and dynamic. - Timeseries requires that the user provides a pre-defined time series for the amount of reserve to be procured in each time step. - Large_failure requires that the user defines the energy flows that could be the largest failure in the system. The highest possible failure (flow multiplied by large_failure_ratio ) in each timestep will then set the reserve requirement for that timestep. - Dynamic means that there is a requirement based on user chosen energy flows - each participating flow is multipled by increase_reserve_ratio and then summed to form the reserve requirement. This can be useful for covering variability within timesteps. Also demand variability can be included through increase_reserve_ratio parameter in reserve__upDown__group relationship. When the same reserve category (e.g. primary upward) has more than one of these (timeseries, large_failure and dynamic) in use, then the largest requirement will apply for that timestep. If they are separated into different reserves, then they need to be fulfilled separately. Reserve requirement is defined for groups of nodes. This means that multiple nodes can have a common reserve requirement (but it is also possible to make a group with only one node). One node can be in multiple groups and therefore subject to multiple overlapping reserve requirements. Only units can generate reserve, but connections can move reserve from one node to another (therefore, there is no impact if the nodes are in the same reserve group, but it can be useful to import reserve from outside the group). Reserve groups For reserve__upDown__group relationships: - reserve_method - Choice of reserve method (timeseries, large_failure, dynamic or their combination). - reservation - [MWh] Amount of reserve required. Constant or time. - reserve_penalty - [\u20ac/MWh] Penalty cost for not fulfilling the reserve requirement. - increase_reserve_ratio - [factor] The reserve is increased by the sum of demands from the group members multiplied by this ratio. Constant. Reserve provision by units For reserve__upDown__unit__node relationships: - is_active - Can the unit provide this reserve. Empty indicates not allowed. Use 'yes' to indicate true. - max_share - [factor] Maximum ratio for the transfer of reserve from the unit to the node. Constant. - reliability - [factor] The share of the reservation that is counted to reserves (sometimes reserve sources are not fully trusted). Constant. - increase_reserve_ratio - [factor] The reserve requirement is increased by the flow between the unit and the node multiplied by this ratio. Constant. - large_failure_ratio - [factor] Each unit using the N-1 failure method will have a separate constraint to require sufficient reserve to cover a failure of the unit generation (multiplied by this ratio). Constant. Reserve transfer by connections For reserve__upDown__connection__node relationships: - is_active - Can the unit provide this reserve. Empty indicates not allowed. Use 'yes' to indicate true. - max_share - [factor] Maximum ratio for the transfer of reserve to this node. Constant. - reliability - [factor] The share of the reservation that is counted to reserves (sometimes reserve sources are not fully trusted). Constant. - increase_reserve_ratio - [factor] The reserve is increased by generation from this unit multiplied this ratio. Constant. - large_failure_ratio - [factor] Each connection using the N-1 failure method will have a separate constraint to require sufficient reserve to cover a failure of the connection (multiplied by this ratio). Constant. Additional objects for further functionality constraint : to create user defined constraints between flow, state, and capacity variables (for nodes, units and connections)","title":"Model parameters"},{"location":"reference/#main-entities-to-define-a-powerenergy-system","text":"Elemental entities (one dimensional): node : maintain a balance between generation, consumption, transfers and storage state changes (nodes can also represent storages) unit : power plants or other conversion devices that take one or more inputs and turn them into one or more outputs connection : transmission lines or other transfer connections between nodes commodity : fuels or other commodities that are either purchased or sold at a price outside of the model scope profile : timeseries that can be used to constraint the behaviour of units, connections or storages reserve : reserve categories to withhold capacity to cope with issues outside of model scope Entities with two or more dimensions: unit__inputNode and unit__outputNode : defines the inputs, outputs and their properties for the conversion units connection__node__node : defines which nodes a connection will connect unit__node__profile and connection__profile : defines a profile limit (upper, lower or fixed) for an energy flow node__profile : defines a profile limit (upper, lower, or fixed) for the storage state of the node commodity__node : defines if a node is a source or sink for a commodity reserve__upDown__unit__node and reserve__upDown__connection__node : reserve capacity from a source to the target node See below for more detailed explanations.","title":"Main entities to define a power/energy system"},{"location":"reference/#how-to-define-the-temporal-properties-of-the-model","text":"","title":"How to define the temporal properties of the model"},{"location":"reference/#timesteps-and-periods","text":"FlexTool has two different kinds of time varying parameters. The first one represents a regular timeline based on timesteps. The duration of each timestep can be defined by the user. There can be multiple timelines in the database - the user needs to define which timeline to use (and what parts of the timeline should be used, as will be explained later). The timestep names in the timeline are defined by the user - they can be abstract like 't0001' or follow a datetime format of choice. However, the timestep names between different timelines must remain unique (usually there should be only one timeline in a database and therefore no issues). The second time varying dimension is period , which is typically used to depict assumptions about the future. One model can include multiple solves that the model will solve in sequence (to allow multi-stage modelling). Each solve can include multiple periods (so that the user can change parameter values for different parts of the future). A parameter of particular type can be either constant/time-varying or constant/period-based. For example inflow is either a constant or time-varying, but it cannot be period-based.","title":"Timesteps and periods"},{"location":"reference/#timeblocksets","text":"Timeblocks pick one or more sections from the timeline to form a timeblockset . Each timeblock defines a start and a duration. The aim of timeblocksets is to allow the modeller to create models with representative periods often used in the investment planning.","title":"Timeblocksets"},{"location":"reference/#definitions","text":"model : model defines the sequence of solves to be performed (e.g. first an investment solve and then a dispatch solve) solves : sequence of solves in the model represented with an array of solve names. discount_offset_investment : [years] Offset from the period (often year) start to the first payment of the investment cost annuity. discount_offset_operations : [years] Offset from the period (often year) start to the payment of operational costs. solve : each solve is built from an array of periods (e.g. one period for 2025 and another for 2030). Periods use timeblocksets to connect with a timeline. period_timeblockset : map of periods with associated timeblocks that will be included in the solve. Index: period name, value: timeblockSet name. realized_periods : these are the periods the model will 'realize' - i.e., what periods will be reported in the results from this solve invest_periods : array of periods where investements are allowed in this solve (applies only to objects that can be invested in) years_represented : Map to indicate how many years the period represents before the next period in the solve. Used for discounting. Can be below one (multiple periods in one year). Index: period, value: years. solver : choice of a solver (a list of possible values) highs_method : HiGHS solver method ('simplex' or 'ipm' which is interior point method). Should use 'choose' for MIP models, since 'simplex' and 'ipm' will not work. highs_parallel : HiGHS parallelises single solves or not ('on' or 'off'). It can be better to turn HiGHS parallel off when executing multiple scnearios in parallel. highs_presolve : HiGHS uses presolve ('on') or not ('off'). Can have a large impact on solution time when solves are large. solve_mode : a single shot or a set of rolling optimisation windows solved in a sequence (not functional yet, always a single shot). timeblockset : timeblocksets are sets of timeblocks with a start (from timeline) and a duration (number of time steps) block_duration a map with index timestep_name that starts the timeblock and value that defines the duration of the block (how many timesteps) timeline : continuous timeline with a user-defined duration for each timestep. Timelines are used by time series data. timestep_duration : a map with timestep_name as an index and duration as a value. timeline_duration_in_years Total duration of the timeline in years. Used to relate operational part of the model with the annualized part of the model. timeblockset__timeline : defines which timeline object particular timeblockset is using.","title":"Definitions"},{"location":"reference/#nodes","text":"","title":"Nodes"},{"location":"reference/#defining-how-the-node-functions","text":"These parameters will define how the node will behave and use the data it is given (available choices are marked in italics ): 'name' - unique name identifier (case sensitive) 'is_active' - is the model/node/unit active in a specific scenario: yes (if not defined, then not active) 'has_balance' - does the node maintain a balance for inputs and outputs: yes (if not defined, then balance is not maintained) 'has_storage' - does the node represent a storage and therefore have a state: yes (if not defined, then no storage) 'invest_method' - Choice of investment method: either not_allowed or then a combination of invest and/or retire investment limits for each period and/or for all periods ( total ) or no_limit 'inflow_method' - choice how to treat inflow time series use_original - does not scale the original time series (no value defaults here) no_inflow - ignores any inserted inflow time series scale_to_annual_flow - will scale the time series to match the annual_flow so that the sum of inflow is multiplied by 8760/ hours_in_solve scale_in_proprotion - calculates a scaling factor by dividing annual_flow with the sum of time series inflow (after it has been annualized using timeline_duration_in_years ) scale_to_annual_and_peak_flow - scales the time series to match the 'annual_flow' target while transforming the time series to match the highest load with the 'peak_inflow'","title":"Defining how the node functions"},{"location":"reference/#data-for-nodes","text":"Input data is set with the following parameters: 'inflow' - [MWh] Inflow into the node (negative is outflow). Constant or time series. 'annual_flow' - [MWh] Annual flow in energy units (always positive, the sign of inflow defines in/out). Constant or period. 'existing' - [MWh] Existing storage capacity (requires has_storage ). Constant. 'invest_cost' - [CUR/kWh] Investment cost for new storage capacity. Constant or period. 'salvage_value' - [CUR/kWh] Salvage value of the storage. Constant or period. 'lifetime' - [years] Life time of the storage unit represented by the node. Constant or period. 'interest_rate' - [unitless, e.g. 0.05 means 5%] Interest rate for investments. Constant or period. 'invest_max_total' - [MWh] Maximum storage investment over all solves. Constant. 'invest_max_period' - [MWh] Maximum storage investment for each period. Period. 'invest_min_total' - [MWh] Minimum storage investment over all solves. Constant. 'invest_min_period' - [MWh] Minimum storage investment for each period. Period. 'invest_forced' - [MWh] Storage capacity that must be invested in a given period. Investment cost will be included in the cost results even though the model does not have an investment variable. Constant or period. 'fixed_cost' - [CUR/kW] Annual fixed cost for storage. Constant or period. 'penalty_up' - [CUR/MWh] Penalty cost for decreasing consumption in the node with a slack variable. Constant or time. 'penalty_down' - [CUR/MWh] Penalty cost for increasing consumption in the node with a slack variable. Constant or time. 'virtual_unitsize' - [MWh] Size of a single storage unit - used for integer investments (lumped investments). If not given, assumed from the existing storage capacity.","title":"Data for nodes"},{"location":"reference/#using-nodes-as-storages","text":"FlexTool manages storages through nodes. A regular node maintains an energy/material balance between all inputs and outputs ( has_balance set to yes ). A storage node includes an additional state variable, which means that the node can also use charging and discharging of the storage while maintaining the energy balance. A storage node is created by setting has_storage to yes and by adding storage capacity using the existing parameter and/or by letting the model invest in storage capacity ( invest_method , invest_cost , invest_max_period , invest_max_total and invest_forced parameters). Since FlexTool allows different temporal structures (multi-periods, rolling optimization, etc.) there needs to be ways to define how the storages behave when the model timeline is not fully consequtive. By default, storages are forced to match start level to the end level within timeblocks. This is an acceptable setting for small storages that do not carry meaningful amounts of energy between longer time periods in the model. There are three methods associated with storage start and end values: storage_binding_method , storage_start_end_method and storage_solve_horizon_method . The most simple one of these is the storage_start_end_method and it overrides the other methods, since it forces the start and/or the end state of the storage to a predefined value based on the proportional parameters storage_state_start and storage_state_end (proportional means that the parameter needs to be set between 0-1 and will be scaled by the storage capacity in the model). These two parameters affect only the first and the last timesteps of the entire model (even when the model has more than one solve). storage_binding_method states how the storage should behave over discontinuities in the model timeline. Model timeline can have jumps for three different reasons: timeblocks, periods, and solves. If storage_binding_method is bind_within_timeblock , then the storage has to match the state of the storage between the beginning and the end of each timeblock. In effect, storage_state_at_start_of_timeblock equals storage_state_at_end_of_timeblock plus charging minus discharging minus self_discharge_loss at the last timestep. Similarly, bind_within_period will force the start and end between periods, but it will treat the jumps between timeblocks as continuous from the storage perspective (the storage will continue from where it was at the end of the previous timeblock). bind_within_solve does effectively the same when there are multiple periods within one solve. bind_within_model (NOT IMPLEMENTED 19.3.2023) will extend the continuity to multiple solves and force the end state of the storage at the end of the last solve to match the beginning state of the storage at the start of the first solve. Finally, bind_forward_only will force continuity in the storage state over the whole model without forcing the end state to match the beginning state. storage_solve_horizon_method is meant for models that roll forward between solves and have an overlapping temporal window between those solves (e.g. a model with 36 hour horizon rolls forward 24 hours at each solve - those 12 last hours will be overwritten by the next solve). In these cases, the end state of the storage will be replaced by the next solve, but it can be valuable to have some guidance for the end level of storage, since it will affect storage behaviour. There are three methods: free is the default and will simply let the model choose where the storage state ends (usually the storage will be emptied, since it would have no monetary value). use_reference_value will use the value set by storage_state_reference_value to force the end state in each solve to match the reference value. use_reference_price will give monetary value for the storage content at the end of the solve horizon set by the storage_state_reference_price parameter - the model is free to choose how much it stores at the end of horizon based on this monetary value. -Method hierarchy: storage_start_end_method storage_binding_method storage_solve_horizon_method Meaning: The storage_binding_method is ignored (exeption bind_forward_only ), if storage_start_end_method has the value fix_start_end , The storage_solve_horizon_method use_reference_value is ignored, if other storage state methods are used. Only exeptions are fix_start or bind_forward_only","title":"Using nodes as storages"},{"location":"reference/#units","text":"Units convert energy (or matter) from one form to another (e.g. open cycle gas turbine), but the can also have multiple inputs and/or outputs (e.g. combined heat and power plant). The input nodes are defined with the relationship unit--inputNode while the output nodes are defined through the relationship unit--outputNode .","title":"Units"},{"location":"reference/#defining-how-the-unit-functions","text":"is_active to state the alternative where the unit becomes active 'conversion_method' to define the way unit converts inputs to outputs startup_method - Choice of startup method. 'Linear' startup means that the unit can start partially (anything between 0 and full capacity) but will face startup cost as well as minimum load limit based on the capacity started up. 'Binary' startup means that the unit is either off or fully on, but it is computationally more demanding than linearized startups. minimum_time_method - Not functional yet. Choice between minimum up- and downtimes ( , min_downtime , min_uptime , both ).","title":"Defining how the unit functions"},{"location":"reference/#main-data-items-for-units","text":"Capacity: existing (and the investment and retirement parameters below) Technical: efficiency , min_load , efficiency_at_min_load , min_uptime , min_downtime min_load - [0-1] Minimum load of the unit. Applies only if the unit has an online variable. With linear startups, it is the share of capacity started up. Constant or time. Economic: startup_cost , fixed_cost (fuel cost comes through the use of fuel commodities and other variable costs are defined for flows between unit and node, see below)","title":"Main data items for units"},{"location":"reference/#investment-parameters-for-capacity-expansion","text":"investment/retirement method invest_cost , interest_rate , lifetime , invest_max_total , invest_max_period , invest_min_total , invest_min_period , invest_forced salvage_value , retire_max_total , retire_max_period , retire_min_total , retire_min_period , retire_forced","title":"Investment parameters (for capacity expansion)"},{"location":"reference/#relationship-of-a-unit-to-a-node-and-determination-of-the-type-of-relationship","text":"If the unit\u2019s outputs are flowing into the node, the node acts as output for the unit. If the unit\u2019s inputs are flowing out of the node (into the unit), the node acts as input for the unit. Not all units necessary have both an input and an output node. E.g. VRE generators have only output nodes and their generation is driven by profiles","title":"Relationship of a unit to a node and determination of the type of relationship"},{"location":"reference/#properties-of-unit-inputnode-and-unit-outputnode-relationships","text":"is_non_synchronous - Chooses whether the unit is synchronously connected to this node. coefficient - [factor] Coefficient to scale the output from a unit to a particular node. Can be used e.g. to change unit of measurement or to remove the flow by using zero as the coefficient (the flow variable can still be used in user constraints). Constant. other_operational_cost - [CUR/MWh] Other operational variable costs for energy flows. Constant or time. inertia_constant - [MWs/MW] Inertia constant for a synchronously connected unit to this node. Constant. ramp_method - Choice of ramp method. 'ramp_limit' poses a limit on the speed of ramp. 'ramp_cost' poses a cost on ramping the flow (NOT FUNCTIONAL AS OF 19.3.2023). ramp_cost - [CUR/MW] Cost of ramping the unit. Constant. ramp_speed_up - [per unit / minute] Maximum ramp up speed. Constant. ramp_speed_down - [per unit / minute] Maximum ramp down speed. Constant.","title":"Properties of unit--inputNode and unit--outputNode relationships"},{"location":"reference/#units-constrained-by-profiles","text":"Some generators (e.g. VRE) are not converting energy from one node to the other. Instead, their generation is determined (or limited) by a specific generation profile set by a profile object with a profile_method , thats state whether the profile forces an upper_limit , lower_limit or equal ity. Finally profile object is given a profile time series (or it can also be a constant). One needs to use node__profile , unit__node__profile or connection__profile to apply the profile to specific energy flow (or storage state in the case of node__profile ).","title":"Units constrained by profiles"},{"location":"reference/#connections","text":"Connections can have an existing transfer capacity as well as an opportunity to invest in new capacity and retire old capacity. The functional choices of connections include the is_active , transfer_method , invest_method , startup_method as well as a choice if the tranfer connection is_DC . Parameters for the connection are defined in the connection object, but the two nodes it connects are defined by establishing a relationship between connection--leftNode--rightNode . existing - [MW] Existing capacity. Constant. efficiency - [factor, typically between 0-1] Efficiency of a connection. Constant or time. constraint_capacity_coefficient - A map of coefficients (Index: constraint name, value: coefficient) to represent the participation of the connection capacity in user-defined constraints. [(invest - divest variable) x coefficient] will be added to the left side of the constraint equation. Invest and divest variables are not multiplied by unitsize. other_operational_cost - [CUR/MWh] Other operational variable cost for trasferring over the connection. Constant or time. fixed_cost - [CUR/kW] Annual fixed cost. Constant or period. invest_cost - [CUR/kW] Investment cost for new 'virtual' capacity. Constant or period. interest_rate - [e.g. 0.05 equals 5%] Interest rate for investments. Constant or period. lifetime - [years] Used to calculate annuity together with interest rate. Constant or period. other investment parameters: invest_max_total , invest_max_period , invest_min_total , invest_min_period , invest_forced , salvage_value is_DC - A flag whether the connection is DC (the flow will not be counted as synchronous if there is a non_synchronous_limit ). Default false. virtual_unitsize - [MW] Size of single connection - used for integer (lumped) investments.","title":"Connections"},{"location":"reference/#commodities","text":"Some nodes can act as a source or a sink of commodities instead of forcing a balance between inputs and outputs. To make that happen, commodities must have a price and be connected to those nodes that serve (or buy) that particular commodity at the given price . In other words, commodity is separate from node so that the user can use the same commodity properties for multiple nodes. Commodities can also have a co2_content . The commodity and its nodes are connected by establishin a new relationship between the commodity and each of its nodes (e.g. coal--coal_market ). price - [CUR/MWh or other unit] Price of the commodity. Constant or period. co2_content - [CO2 ton per MWh] Constant.","title":"Commodities"},{"location":"reference/#groups","text":"Groups are used to make constraints that apply to a group of nodes, units and/or connections. A group is defined by creating a group object and then creating a relationship between the group and its members. The membership relationship classes are group__node , group__unit , group__connection , group__unit__node , group__connection__node and reserve__upDown__group . The choice of group members depends on what the group is trying to achieve. For instance a group that limits investments could have a set of units included in the group.","title":"Groups"},{"location":"reference/#capacity-limits-for-nodes-units-and-connections","text":"invest_method - the choice of method how to limit or force investments in capacity [MW or MWh] of the group members invest_max_total - [MW or MWh] Maximum investment to the virtual capacity of a group of units or to the storage capacity of a group of nodes. Total over all solves. invest_max_period - [MW or MWh] Maximum investment per period to the virtual capacity of a group of units or to the storage capacity of a group of nodes. invest_min_total - [MW or MWh] Minimum investment to the virtual capacity of a group of units or to the storage capacity of a group of nodes. Total over all solves. invest_min_period - [MW or MWh] Minimum investment per period to the virtual capacity of a group of units or to the storage capacity of a group of nodes.","title":"Capacity limits for nodes, units and connections"},{"location":"reference/#cumulative-and-instant-flow-limits-for-unit__nodes-and-connection__nodes","text":"max_cumulative_flow - [MW] Limits the maximum cumulative flow for a group of connection_nodes and/or unit_nodes. It needs to be expressed as average flow, since the limit is multiplied by the model duration to get the cumulative limit (e.g. by 8760 if a single year is modelled). Applied for each solve. Constant or period. min_cumulative_flow - [MW] Limits the minimum cumulative flow for a group of connection_nodes and/or unit_nodes. It needs to be expressed as average flow, since the limit is multiplied by the model duration to get the cumulative limit (e.g. by 8760 if a single year is modelled). Applied for each solve. Constant or period. max_instant_flow - [MW] Maximum instantenous flow for the aggregated flow of all group members. Constant or period. min_instant_flow - [MW] Minimum instantenous flow for the aggregated flow of all group members. Constant or period.","title":"Cumulative and instant flow limits for unit__nodes and connection__nodes"},{"location":"reference/#limits-for-nodes","text":"has_inertia - A flag whether the group of nodes has an inertia constraint active. inertia_limit - [MWs] Minimum for synchronous inertia in the group of nodes. Constant or period. penalty_inertia - [CUR/MWs] Penalty for violating the inertia constraint. Constant or period. has_non_synchronous - A flag whether the group of nodes has the non-synchronous share constraint active. non_synchronous_limit - [share, e.g. 0.8 means 80%] The maximum share of non-synchronous generation in the node group. Constant or period. penalty_non_synchronous - [CUR/MWh] Penalty for violating the non synchronous constraint. Constant or period. has_capacity_margin - A flag whether the group of nodes has a capacity margin constraint in the investment mode. capacity_margin - [MW] How much capacity a node group is required to have in addition to the peak net load in the investment time series. Used only by the investment mode. Constant or period. penalty_capacity_margin - [CUR/MWh] Penalty for violating the capacity margin constraint. Constant or period.","title":"Limits for nodes"},{"location":"reference/#co2-costs-and-limits","text":"co2_method - Choice of the CO2 method or a combination of methods: no_method, price, period, total, price_period, price_total, period_total, price_period_total. co2_price [CUR/ton] CO2 price for a group of nodes. Constant or period. co2_max_period [tCO2] Maximum limit for emitted CO2 in each period. co2_max_total [tCO2] Maximum limit for emitted CO2 in the whole solve.","title":"CO2 costs and limits"},{"location":"reference/#controlling-outputs","text":"Some results are output for groups of nodes. This means that instead of getting output for each node separately, nodes can be grouped and the aggregated results can be examined. For example all electricity nodes could be groupped for aggragated output. output_results - A flag to output aggregated results for the group members.","title":"Controlling outputs"},{"location":"reference/#reserves","text":"The user defines reserve categories through reserve object. Reserves are reservations of capacity (either upward or downward) and that capacity will not therefore be available for other use (flowing energy or commodities). There are three different ways how a reserve requirement can be calculated: timeseries, large_failure and dynamic. - Timeseries requires that the user provides a pre-defined time series for the amount of reserve to be procured in each time step. - Large_failure requires that the user defines the energy flows that could be the largest failure in the system. The highest possible failure (flow multiplied by large_failure_ratio ) in each timestep will then set the reserve requirement for that timestep. - Dynamic means that there is a requirement based on user chosen energy flows - each participating flow is multipled by increase_reserve_ratio and then summed to form the reserve requirement. This can be useful for covering variability within timesteps. Also demand variability can be included through increase_reserve_ratio parameter in reserve__upDown__group relationship. When the same reserve category (e.g. primary upward) has more than one of these (timeseries, large_failure and dynamic) in use, then the largest requirement will apply for that timestep. If they are separated into different reserves, then they need to be fulfilled separately. Reserve requirement is defined for groups of nodes. This means that multiple nodes can have a common reserve requirement (but it is also possible to make a group with only one node). One node can be in multiple groups and therefore subject to multiple overlapping reserve requirements. Only units can generate reserve, but connections can move reserve from one node to another (therefore, there is no impact if the nodes are in the same reserve group, but it can be useful to import reserve from outside the group).","title":"Reserves"},{"location":"reference/#reserve-groups","text":"For reserve__upDown__group relationships: - reserve_method - Choice of reserve method (timeseries, large_failure, dynamic or their combination). - reservation - [MWh] Amount of reserve required. Constant or time. - reserve_penalty - [\u20ac/MWh] Penalty cost for not fulfilling the reserve requirement. - increase_reserve_ratio - [factor] The reserve is increased by the sum of demands from the group members multiplied by this ratio. Constant.","title":"Reserve groups"},{"location":"reference/#reserve-provision-by-units","text":"For reserve__upDown__unit__node relationships: - is_active - Can the unit provide this reserve. Empty indicates not allowed. Use 'yes' to indicate true. - max_share - [factor] Maximum ratio for the transfer of reserve from the unit to the node. Constant. - reliability - [factor] The share of the reservation that is counted to reserves (sometimes reserve sources are not fully trusted). Constant. - increase_reserve_ratio - [factor] The reserve requirement is increased by the flow between the unit and the node multiplied by this ratio. Constant. - large_failure_ratio - [factor] Each unit using the N-1 failure method will have a separate constraint to require sufficient reserve to cover a failure of the unit generation (multiplied by this ratio). Constant.","title":"Reserve provision by units"},{"location":"reference/#reserve-transfer-by-connections","text":"For reserve__upDown__connection__node relationships: - is_active - Can the unit provide this reserve. Empty indicates not allowed. Use 'yes' to indicate true. - max_share - [factor] Maximum ratio for the transfer of reserve to this node. Constant. - reliability - [factor] The share of the reservation that is counted to reserves (sometimes reserve sources are not fully trusted). Constant. - increase_reserve_ratio - [factor] The reserve is increased by generation from this unit multiplied this ratio. Constant. - large_failure_ratio - [factor] Each connection using the N-1 failure method will have a separate constraint to require sufficient reserve to cover a failure of the connection (multiplied by this ratio). Constant.","title":"Reserve transfer by connections"},{"location":"reference/#additional-objects-for-further-functionality","text":"constraint : to create user defined constraints between flow, state, and capacity variables (for nodes, units and connections)","title":"Additional objects for further functionality"},{"location":"results/","text":"Results FlexTool outputs results typical to a planning model or a scheduling model, but it also tries to highlight potential flexibility issues in the system. The outputs from the latest run are initially CSV files and can befound in the folder 'output'. File 'summary_solve.csv' can give a quick overview of potential issues in the solve - it is a diagnostic file. The other files are all numerical results and will be imported to a Spine database by the FlexTool workflow. Costs Prices Energy flows Energy balance in nodes Group results Capacity and investment results CO2 emissions Reserves Inertia and non-synchronous generation Ramps Slack and penalty values Costs model object cost parameter - [CUR] includes annualized total cost as well as annualized costs divided into unit investment/retirement - [CUR] cost of investing in unit capacity or benefits from salvaging unit capacity connection investment/retirement - [CUR] cost of investing in connection capacity or benefits from salvaging connection capacity storage investment/retirement - [CUR] cost of investing in storage capacity or benefits from salvaging storage capacity commodity - [CUR] cost of unit using commodity inputs or benefit of selling commodities (negative value) CO2 - [CUR] cost of CO2 emissions caused by unit using commodities with CO2 content variable cost - [CUR] other variable operation and maintenance costs starts - [CUR] start up costs upward penalty - [CUR] cost of involuntary demand reduction downward penalty - [CUR] cost of involuntary demand increase inertia penalty - [CUR] cost of not meeting the inertia constraint non-synchronous penalty - [CUR] cost of not meeting the non-synchronous constraint capacity margin penalty - [CUR] cost of not meeting the capacity margin constraint upward reserve penalty - [CUR] cost of not meeting the upward reserve constraint downward reserve penalty - [CUR] cost of not meeting the downward reserve constraint model object cost_t parameter - [CUR] similar as above but costs given for each timestep (no investment/retirement costs) Prices node object price_t parameter - [CUR/MWh] each node that maintains an energy balance provides a price time series based on the marginal value of the balance constraint Energy flows unit__node relationship flow parameter - [MWh] cumulative flow from the node (if node is input) or to the node (if node is output) unit__node relationship flow_t parameter - [MWh] flow from the node (if node is input) or to the node (if node is output) connection__node__node relationship flow parameter - [MWh] cumulative flow through the connection (left to right is positive) connection__node__node relationship flow_t parameter - [MWh] flow through the connection (left to right is positive) Energy balance in nodes node object balance parameter - [MWh] cumulative inputs (positive) and outputs (negative) to the node from all the possible sources ( from_units , from_connection , to_units , to_connections , state change over the period, self discharge during the period, upward slack for involuntary demand reduction and downward slack for involuntary demand increase) node object balance_t parameter - [MWh] same as above, but for each timestep node object state_t parameter - [MWh] storage state of the node in each timestep node object state_t parameter - storage state of the node in each timestep (typically MWh). Unit online and startup unit object online_average parameter - [count] average online status of the unit (average number of units online during the period) unit object online_t parameter - [count] online status of the unit (number of units online in each timestep) unit object startup_cumulative parameter - [count] cumulative number of unit startups during the period Group results group object indicator parameter - gives a set of results for all node members of the group sum of annualized inflows - [MWh] sum of inflow to the node which has been annualized (scaled to correspond to a year of timesteps) VRE share - [0-1] how much the flows from VRE sources (inputs using 'upper limit' profile) are of the inflow curtailed VRE share - [0-1] how much the unused flows from VRE sources would have been of the inflow upward slack share - [0-1] upward slack in relation to the inflow downward slack share - [0-1] downward slack in relation to the inflow Capacity and investment results unit , connection and node objects capacity parameter - [MW or MWh] include the following parameters existing - [MW or MWh] capacity that was assumed to exist in the beginning of the solve invested - [MW or MWh] capacity the model decided to invest for the given period retired - [MW or MWh] capacity the model decided to retire in the beginning of the given period total - [MW or MWh] sum of existing , invested and retired capacities unit , connection and node objects invest_marginal parameter - [CUR/MW or MWh] marginal cost to invest in one more MW or MWh of capacity (zero value means that the model has invested in optimal amount; negative value means that if the model would be able to invest more, it could reduce total cost by the stated amount per MW or MWh; positive value means the cost is higher than the benefit by the stated amount per MW or MWh) group parameter slack_capacity_margin - [MW or MWh] use of slack variable and the associated penalty cost to meet the capacity margin requirement in the period group parameter slack_capacity_margin - use of slack variable and the associated penalty cost to meet the capacity margin requirement in the period CO2 emissions unit object co2 parameter - [tCO2] how many tons of CO2 the unit has generated (by using commodity with CO2 content) or removed Reserves unit__reserve__upDown__node relationship reservation_t parameter - [MW] how much upward or downward reserve particular unit was providing to a particular node in given timestep unit__reserve__upDown__node relationship reservation_average parameter - [MW] how much upward or downward reserve particular unit was providing to a particular node in average during the period group__reserve__upDown relationship slack_reserve_t parameter - [MW] use of slack variable and the associated penalty cost to fulfill the upward or downward reserve requirement in each timestep group__reserve__upDown relationship slack_reserve parameter - [MW] cumulative use of slack variable and the associated penalty cost to fulfill the upward or downward reserve requirement during the period Inertia and non-synchronous generation group object inertia_t parameter - [MWs] the amount of inertia (MWs) in the group of nodes in each timestep group object slack_inertia_t parameter - [MWs] use of slack variable and the associated penalty cost to fulfill the inertia requirement in each timestep group object slack_nonsync_t parameter - [MWh] use of slack variable and the associated penalty cost to fulfill the non-synchronous share maximum share constraint in each timestep Ramps node object ramp_t parameter - includes seven parameters that form the ramp room envelope (how much there is additional room to ramp in a give node) ramp - [MW] the actual ramp in the node from previous timestep to this timestep units_up - [MW] additional room for upward ramps from non-VRE units connected to the node VRE_up - [MW] adds upward ramp room from VRE units on top of the ramp room from non-VRE units connections_up - [MW] adds upward ramp room from connections on top of the previous ramp rooms (does not consider whether the connected node has ramp room, but is simply the available capacity in the connection) units_down - [MW] additional room for downward ramps from non-VRE units connected to the node VRE_down - [MW] adds downward ramp room from VRE units on top of the ramp room from non-VRE units connections_down - [MW] adds downward ramp room from connections on top of the previous ramp rooms (does not consider whether the connected node has ramp room, but is simply the available capacity in the connection) unit__node relationship ramp_t parameter - [MW] shows ramping of particular input or output flow between a unit and a node for each time step Slack and penalty values Slack and penalty values are listed in various places above (costs, energy balance, reserves, inertia and non-sychronous generation).","title":"Model outputs"},{"location":"results/#results","text":"FlexTool outputs results typical to a planning model or a scheduling model, but it also tries to highlight potential flexibility issues in the system. The outputs from the latest run are initially CSV files and can befound in the folder 'output'. File 'summary_solve.csv' can give a quick overview of potential issues in the solve - it is a diagnostic file. The other files are all numerical results and will be imported to a Spine database by the FlexTool workflow. Costs Prices Energy flows Energy balance in nodes Group results Capacity and investment results CO2 emissions Reserves Inertia and non-synchronous generation Ramps Slack and penalty values","title":"Results"},{"location":"results/#costs","text":"model object cost parameter - [CUR] includes annualized total cost as well as annualized costs divided into unit investment/retirement - [CUR] cost of investing in unit capacity or benefits from salvaging unit capacity connection investment/retirement - [CUR] cost of investing in connection capacity or benefits from salvaging connection capacity storage investment/retirement - [CUR] cost of investing in storage capacity or benefits from salvaging storage capacity commodity - [CUR] cost of unit using commodity inputs or benefit of selling commodities (negative value) CO2 - [CUR] cost of CO2 emissions caused by unit using commodities with CO2 content variable cost - [CUR] other variable operation and maintenance costs starts - [CUR] start up costs upward penalty - [CUR] cost of involuntary demand reduction downward penalty - [CUR] cost of involuntary demand increase inertia penalty - [CUR] cost of not meeting the inertia constraint non-synchronous penalty - [CUR] cost of not meeting the non-synchronous constraint capacity margin penalty - [CUR] cost of not meeting the capacity margin constraint upward reserve penalty - [CUR] cost of not meeting the upward reserve constraint downward reserve penalty - [CUR] cost of not meeting the downward reserve constraint model object cost_t parameter - [CUR] similar as above but costs given for each timestep (no investment/retirement costs)","title":"Costs"},{"location":"results/#prices","text":"node object price_t parameter - [CUR/MWh] each node that maintains an energy balance provides a price time series based on the marginal value of the balance constraint","title":"Prices"},{"location":"results/#energy-flows","text":"unit__node relationship flow parameter - [MWh] cumulative flow from the node (if node is input) or to the node (if node is output) unit__node relationship flow_t parameter - [MWh] flow from the node (if node is input) or to the node (if node is output) connection__node__node relationship flow parameter - [MWh] cumulative flow through the connection (left to right is positive) connection__node__node relationship flow_t parameter - [MWh] flow through the connection (left to right is positive)","title":"Energy flows"},{"location":"results/#energy-balance-in-nodes","text":"node object balance parameter - [MWh] cumulative inputs (positive) and outputs (negative) to the node from all the possible sources ( from_units , from_connection , to_units , to_connections , state change over the period, self discharge during the period, upward slack for involuntary demand reduction and downward slack for involuntary demand increase) node object balance_t parameter - [MWh] same as above, but for each timestep node object state_t parameter - [MWh] storage state of the node in each timestep node object state_t parameter - storage state of the node in each timestep (typically MWh).","title":"Energy balance in nodes"},{"location":"results/#unit-online-and-startup","text":"unit object online_average parameter - [count] average online status of the unit (average number of units online during the period) unit object online_t parameter - [count] online status of the unit (number of units online in each timestep) unit object startup_cumulative parameter - [count] cumulative number of unit startups during the period","title":"Unit online and startup"},{"location":"results/#group-results","text":"group object indicator parameter - gives a set of results for all node members of the group sum of annualized inflows - [MWh] sum of inflow to the node which has been annualized (scaled to correspond to a year of timesteps) VRE share - [0-1] how much the flows from VRE sources (inputs using 'upper limit' profile) are of the inflow curtailed VRE share - [0-1] how much the unused flows from VRE sources would have been of the inflow upward slack share - [0-1] upward slack in relation to the inflow downward slack share - [0-1] downward slack in relation to the inflow","title":"Group results"},{"location":"results/#capacity-and-investment-results","text":"unit , connection and node objects capacity parameter - [MW or MWh] include the following parameters existing - [MW or MWh] capacity that was assumed to exist in the beginning of the solve invested - [MW or MWh] capacity the model decided to invest for the given period retired - [MW or MWh] capacity the model decided to retire in the beginning of the given period total - [MW or MWh] sum of existing , invested and retired capacities unit , connection and node objects invest_marginal parameter - [CUR/MW or MWh] marginal cost to invest in one more MW or MWh of capacity (zero value means that the model has invested in optimal amount; negative value means that if the model would be able to invest more, it could reduce total cost by the stated amount per MW or MWh; positive value means the cost is higher than the benefit by the stated amount per MW or MWh) group parameter slack_capacity_margin - [MW or MWh] use of slack variable and the associated penalty cost to meet the capacity margin requirement in the period group parameter slack_capacity_margin - use of slack variable and the associated penalty cost to meet the capacity margin requirement in the period","title":"Capacity and investment results"},{"location":"results/#co2-emissions","text":"unit object co2 parameter - [tCO2] how many tons of CO2 the unit has generated (by using commodity with CO2 content) or removed","title":"CO2 emissions"},{"location":"results/#reserves","text":"unit__reserve__upDown__node relationship reservation_t parameter - [MW] how much upward or downward reserve particular unit was providing to a particular node in given timestep unit__reserve__upDown__node relationship reservation_average parameter - [MW] how much upward or downward reserve particular unit was providing to a particular node in average during the period group__reserve__upDown relationship slack_reserve_t parameter - [MW] use of slack variable and the associated penalty cost to fulfill the upward or downward reserve requirement in each timestep group__reserve__upDown relationship slack_reserve parameter - [MW] cumulative use of slack variable and the associated penalty cost to fulfill the upward or downward reserve requirement during the period","title":"Reserves"},{"location":"results/#inertia-and-non-synchronous-generation","text":"group object inertia_t parameter - [MWs] the amount of inertia (MWs) in the group of nodes in each timestep group object slack_inertia_t parameter - [MWs] use of slack variable and the associated penalty cost to fulfill the inertia requirement in each timestep group object slack_nonsync_t parameter - [MWh] use of slack variable and the associated penalty cost to fulfill the non-synchronous share maximum share constraint in each timestep","title":"Inertia and non-synchronous generation"},{"location":"results/#ramps","text":"node object ramp_t parameter - includes seven parameters that form the ramp room envelope (how much there is additional room to ramp in a give node) ramp - [MW] the actual ramp in the node from previous timestep to this timestep units_up - [MW] additional room for upward ramps from non-VRE units connected to the node VRE_up - [MW] adds upward ramp room from VRE units on top of the ramp room from non-VRE units connections_up - [MW] adds upward ramp room from connections on top of the previous ramp rooms (does not consider whether the connected node has ramp room, but is simply the available capacity in the connection) units_down - [MW] additional room for downward ramps from non-VRE units connected to the node VRE_down - [MW] adds downward ramp room from VRE units on top of the ramp room from non-VRE units connections_down - [MW] adds downward ramp room from connections on top of the previous ramp rooms (does not consider whether the connected node has ramp room, but is simply the available capacity in the connection) unit__node relationship ramp_t parameter - [MW] shows ramping of particular input or output flow between a unit and a node for each time step","title":"Ramps"},{"location":"results/#slack-and-penalty-values","text":"Slack and penalty values are listed in various places above (costs, energy balance, reserves, inertia and non-sychronous generation).","title":"Slack and penalty values"},{"location":"spine_database/","text":"Data structure in Spine databases Spine databases use Entity-Attribute-Value with Classes and Relationships (EAV-CR). Entity classes define the categories of data. These can be one-dimensional object classes (e.g. node or unit ) or multi-dimensional relationship classes formed from the object classes (e.g. unit__node ). Spine Toolbox user can define these classes to suit their modelling needs. For FlexTool the entity classes have been pre-defined. Instead, FlexTool user needs to add the entity instances: objects and relationships that define the particular network structure to be modelled (e.g. coal_plant unit or west node ). Furthermore, each entity class (object or relationship) can hold only parameters that have been defined for that particular class. Again, FlexTool user does not need to add the parameter types - the user should just add needed parameter values for the entities the user has created. Database editor in brief Spine Toolbox database editor can be used to modify data and to build scenarios. The figure below shows an example where parameter data from two alternatives have been selected for display (in the data table). The object tree on the left selects two nodes ('coal_market' and 'west') as well as one unit ('coal_plant'). Consequently, one can use both whole classes and individual entities (members of the classes) as data filters. The results of this filter are visualized in the graph on top. The mouse pointer is showing a relationship entity that connects the 'coal_plant' and its output node 'west'. The relationship entity is defined in a relationship tree, which is not visible here. The scenario tree (on the right, below the alternative tree) shows that the 'coal' scenario is formed by taking all data from the 'init' alternative and then all data from the 'coal' alternative . If there would be same parameter defined for both scenarios , then the latter alternative would overwrite the first alternative . Whenever data is modified, the data is staged in separate database tables (although not directly visible to user). The changes will be applied only once the user commits the changes and leaves a commit message to indicate what has been done. The commit can be done with ctrl-enter or from the database editor menu (triple bar at top-right). The database editor menu has options for how to display the data: table view, different pivot views and a graph view. It also contains a tool to delete data ( purge ) and decrease database size by removing unused allocations ( vacuum ). You can also bring back dock windows that have been closed by the user. History will show the history of data changes based on the commits made by the user. More on Spine Database editor in https://spine-toolbox.readthedocs.io/en/latest/spine_db_editor/index.html.","title":"Data structure in Spine databases"},{"location":"spine_database/#data-structure-in-spine-databases","text":"Spine databases use Entity-Attribute-Value with Classes and Relationships (EAV-CR). Entity classes define the categories of data. These can be one-dimensional object classes (e.g. node or unit ) or multi-dimensional relationship classes formed from the object classes (e.g. unit__node ). Spine Toolbox user can define these classes to suit their modelling needs. For FlexTool the entity classes have been pre-defined. Instead, FlexTool user needs to add the entity instances: objects and relationships that define the particular network structure to be modelled (e.g. coal_plant unit or west node ). Furthermore, each entity class (object or relationship) can hold only parameters that have been defined for that particular class. Again, FlexTool user does not need to add the parameter types - the user should just add needed parameter values for the entities the user has created.","title":"Data structure in Spine databases"},{"location":"spine_database/#database-editor-in-brief","text":"Spine Toolbox database editor can be used to modify data and to build scenarios. The figure below shows an example where parameter data from two alternatives have been selected for display (in the data table). The object tree on the left selects two nodes ('coal_market' and 'west') as well as one unit ('coal_plant'). Consequently, one can use both whole classes and individual entities (members of the classes) as data filters. The results of this filter are visualized in the graph on top. The mouse pointer is showing a relationship entity that connects the 'coal_plant' and its output node 'west'. The relationship entity is defined in a relationship tree, which is not visible here. The scenario tree (on the right, below the alternative tree) shows that the 'coal' scenario is formed by taking all data from the 'init' alternative and then all data from the 'coal' alternative . If there would be same parameter defined for both scenarios , then the latter alternative would overwrite the first alternative . Whenever data is modified, the data is staged in separate database tables (although not directly visible to user). The changes will be applied only once the user commits the changes and leaves a commit message to indicate what has been done. The commit can be done with ctrl-enter or from the database editor menu (triple bar at top-right). The database editor menu has options for how to display the data: table view, different pivot views and a graph view. It also contains a tool to delete data ( purge ) and decrease database size by removing unused allocations ( vacuum ). You can also bring back dock windows that have been closed by the user. History will show the history of data changes based on the commits made by the user. More on Spine Database editor in https://spine-toolbox.readthedocs.io/en/latest/spine_db_editor/index.html.","title":"Database editor in brief"},{"location":"spine_toolbox/","text":"IRENA FlexTool workflow shortly explained IRENA FlexTool workflow is a Spine Toolbox workflow that can be modified by the user. The workflow provided in the repository is a template Spine Toolbox project that can be either copied for local changes or the workflow data input data files can be switched to local files. It is also possible to work directly with the template, but then one needs to be careful when pulling a new version of IRENA FlexTool since that can overwrite local changes (the input data file contents need to be copied to safety before updating). If you are using the IRENA FlexTool browser-interface , then you will not directly see the Spine Toolbox workflow, but the FlexTool web-server will be executing parts of the workflow in the background as you develop and run the model. The panel on the right shows the different scenarios that are available in the database. The user can choose which scenarios will be processed by the workflow (until item Results , which combines the results into one database). Spine Toolbox can execute scenarios in parallel (as long as using 'work directories' is defined in FlexTool item). Input data workflow item points to a sqlite file that needs to have IRENA FlexTool data format (that uses Spine Toolbox database definition). The template file has the right format and contains empty object classes corresponding to FlexTool data structure as well as parameters available in each object class. Double clicking the Input data workflow item will open the database editor. Just selecting the Input data workflow item allows one to change the file (make a copy of the existing Input_data.sqlite using the file system of your OS and point to the copy). Init workflow item points to a sqlite file with predefined data that showcases IRENA FlexTool functionality. Some of the scenarios from there are used in the user guide. Initialize copies the contents of the Init database to the Input data database. The scenario filter in the arrow after the Init database can be used to choose what data will be copied. Export_to_csv workflow item is a Spine Toolbox exporter that has been set to write csv files that IRENA FlexTool model code will read. FlexTool workflow item contains a Python script that calls FlexTool model code for each solve and passes data between these solves. FlexTool model is written in MathProg and it calls HiGHS solver by default to solve the model. The outputs are csv files. Import_results is a Spine Toolbox importer that takes the output csv files and writes them in the Results database. Excel_input_data and Import_from_Excel allow users to use Excel as an interface for the input data. They are optional parts of the workflow. To_Excel worfklow item will export most scenario results to a simple Excel file. One way to utilize this is by creating another Excel file that draws figures from the result Excel file that is then updated by the workflow. The browser interface of FlexTool also runs part of this same workflow ( Export_to_csv --> FlexTool --> Import_results ). The server takes a copy of the workflow (inside the user_projects) folder and uses Spine Toolbox to execute the scenarios. More instructions for Spine Toolbox in https://spine-toolbox.readthedocs.io/en/latest/?badge=latest. Data structure in Spine databases Spine databases use Entity-Attribute-Value with Classes and Relationships (EAV-CR). Entity classes define the categories of data. These can be one-dimensional object classes (e.g. node or unit ) or multi-dimensional relationship classes formed from the object classes (e.g. unit__node ). Spine Toolbox user can define these classes to suit their modelling needs. For FlexTool the entity classes have been pre-defined. Instead, FlexTool user needs to add the entity instances: objects and relationships that define the particular network structure to be modelled (e.g. coal_plant unit or west node ). Furthermore, each entity class (object or relationship) can hold only parameters that have been defined for that particular class. Again, FlexTool user does not need to add the parameter types - the user should just add needed parameter values for the entities the user has created. Database editor in brief Spine Toolbox database editor can be used to modify data and to build scenarios. The figure below shows an example where parameter data from two alternatives have been selected for display (in the data table). The object tree on the left selects two nodes ('coal_market' and 'west') as well as one unit ('coal_plant'). Consequently, one can use both whole classes and individual entities (members of the classes) as data filters. The results of this filter are visualized in the graph on top. The mouse pointer is showing a relationship entity that connects the 'coal_plant' and its output node 'west'. The relationship entity is defined in a relationship tree, which is not visible here. The scenario tree (on the right, below the alternative tree) shows that the 'coal' scenario is formed by taking all data from the 'init' alternative and then all data from the 'coal' alternative . If there would be same parameter defined for both scenarios , then the latter alternative would overwrite the first alternative . Whenever data is modified, the data is staged in separate database tables (although not directly visible to user). The changes will be applied only once the user commits the changes and leaves a commit message to indicate what has been done. The commit can be done with ctrl-enter or from the database editor menu (triple bar at top-right). The database editor menu has options for how to display the data: table view, different pivot views and a graph view. It also contains a tool to delete data ( purge ) and decrease database size by removing unused allocations ( vacuum ). You can also bring back dock windows that have been closed by the user. History will show the history of data changes based on the commits made by the user. More on Spine Database editor in https://spine-toolbox.readthedocs.io/en/latest/spine_db_editor/index.html.","title":"Toolbox interface"},{"location":"spine_toolbox/#irena-flextool-workflow-shortly-explained","text":"IRENA FlexTool workflow is a Spine Toolbox workflow that can be modified by the user. The workflow provided in the repository is a template Spine Toolbox project that can be either copied for local changes or the workflow data input data files can be switched to local files. It is also possible to work directly with the template, but then one needs to be careful when pulling a new version of IRENA FlexTool since that can overwrite local changes (the input data file contents need to be copied to safety before updating). If you are using the IRENA FlexTool browser-interface , then you will not directly see the Spine Toolbox workflow, but the FlexTool web-server will be executing parts of the workflow in the background as you develop and run the model. The panel on the right shows the different scenarios that are available in the database. The user can choose which scenarios will be processed by the workflow (until item Results , which combines the results into one database). Spine Toolbox can execute scenarios in parallel (as long as using 'work directories' is defined in FlexTool item). Input data workflow item points to a sqlite file that needs to have IRENA FlexTool data format (that uses Spine Toolbox database definition). The template file has the right format and contains empty object classes corresponding to FlexTool data structure as well as parameters available in each object class. Double clicking the Input data workflow item will open the database editor. Just selecting the Input data workflow item allows one to change the file (make a copy of the existing Input_data.sqlite using the file system of your OS and point to the copy). Init workflow item points to a sqlite file with predefined data that showcases IRENA FlexTool functionality. Some of the scenarios from there are used in the user guide. Initialize copies the contents of the Init database to the Input data database. The scenario filter in the arrow after the Init database can be used to choose what data will be copied. Export_to_csv workflow item is a Spine Toolbox exporter that has been set to write csv files that IRENA FlexTool model code will read. FlexTool workflow item contains a Python script that calls FlexTool model code for each solve and passes data between these solves. FlexTool model is written in MathProg and it calls HiGHS solver by default to solve the model. The outputs are csv files. Import_results is a Spine Toolbox importer that takes the output csv files and writes them in the Results database. Excel_input_data and Import_from_Excel allow users to use Excel as an interface for the input data. They are optional parts of the workflow. To_Excel worfklow item will export most scenario results to a simple Excel file. One way to utilize this is by creating another Excel file that draws figures from the result Excel file that is then updated by the workflow. The browser interface of FlexTool also runs part of this same workflow ( Export_to_csv --> FlexTool --> Import_results ). The server takes a copy of the workflow (inside the user_projects) folder and uses Spine Toolbox to execute the scenarios. More instructions for Spine Toolbox in https://spine-toolbox.readthedocs.io/en/latest/?badge=latest.","title":"IRENA FlexTool workflow shortly explained"},{"location":"spine_toolbox/#data-structure-in-spine-databases","text":"Spine databases use Entity-Attribute-Value with Classes and Relationships (EAV-CR). Entity classes define the categories of data. These can be one-dimensional object classes (e.g. node or unit ) or multi-dimensional relationship classes formed from the object classes (e.g. unit__node ). Spine Toolbox user can define these classes to suit their modelling needs. For FlexTool the entity classes have been pre-defined. Instead, FlexTool user needs to add the entity instances: objects and relationships that define the particular network structure to be modelled (e.g. coal_plant unit or west node ). Furthermore, each entity class (object or relationship) can hold only parameters that have been defined for that particular class. Again, FlexTool user does not need to add the parameter types - the user should just add needed parameter values for the entities the user has created.","title":"Data structure in Spine databases"},{"location":"spine_toolbox/#database-editor-in-brief","text":"Spine Toolbox database editor can be used to modify data and to build scenarios. The figure below shows an example where parameter data from two alternatives have been selected for display (in the data table). The object tree on the left selects two nodes ('coal_market' and 'west') as well as one unit ('coal_plant'). Consequently, one can use both whole classes and individual entities (members of the classes) as data filters. The results of this filter are visualized in the graph on top. The mouse pointer is showing a relationship entity that connects the 'coal_plant' and its output node 'west'. The relationship entity is defined in a relationship tree, which is not visible here. The scenario tree (on the right, below the alternative tree) shows that the 'coal' scenario is formed by taking all data from the 'init' alternative and then all data from the 'coal' alternative . If there would be same parameter defined for both scenarios , then the latter alternative would overwrite the first alternative . Whenever data is modified, the data is staged in separate database tables (although not directly visible to user). The changes will be applied only once the user commits the changes and leaves a commit message to indicate what has been done. The commit can be done with ctrl-enter or from the database editor menu (triple bar at top-right). The database editor menu has options for how to display the data: table view, different pivot views and a graph view. It also contains a tool to delete data ( purge ) and decrease database size by removing unused allocations ( vacuum ). You can also bring back dock windows that have been closed by the user. History will show the history of data changes based on the commits made by the user. More on Spine Database editor in https://spine-toolbox.readthedocs.io/en/latest/spine_db_editor/index.html.","title":"Database editor in brief"},{"location":"tutorial/","text":"IRENA FlexTool tutorial The instructions for installing IRENA FlexTool are here . This user guide will build a small system step-by-step. It assumes you will be using Spine Toolbox as the front-end. If you are using the IRENA FlexTool web-interface, the instructions still apply, but the example figures in this tutorial will not be as helpful. IRENA FlexTool concepts are explained in more depth at this page . Video tutorial for Building a small test system can be watched here . The small system to be built is also directly available in the FlexTool repository ( Init SQLite database) and can be opened with the Spine Toolbox database editor. The default workflow for IRENA FlexTool executes the scenarios from the Input data database (and not from the Init SQLite database). The Input data database is empty by default. Therefore, if you want to use directly the contents of the Init database (instead of building the small system step-by-step), you need to copy them to the Input data database before running the scenarios in this tutorial. To copy the data, you need to execute the Initialize workflow item: select the item, press Execute selection from the toolbar. It is not advised to run the whole workflow, ( Execute project ) since it will copy data from two sources: the Excel based input data file and the Init database and this will create two sets of data in the Input data database. More information on how to set-up and use the Spine Toolbox front-end in here . If not done already, in the flextool folder make a copy of the Results_template.sqlite and rename it Results.sqlite. Remark: in case you had already populated the Input data database, you need to delete the data before importing from Init SQLite database. This can be done with the 'purge' tool from the Database Editor menu: in purge , click on both Select entity and value items , and Select scenario items and then purge. Building a small test system 1st step - a node with no units 2nd step - add a coal unit 3rd step - add a wind power plant 4th step - add a network 5th step - add a reserve More functionality Adding a storage unit (battery) Adding battery investment capabilities Minimum load example Adding CO2 emissions and costs Full year model A system with coal, wind, network, battery and CO2 over a full year Representative periods Multi-year model Discount calculations Building a small test system This tutorial can be used in couple of different ways - the best way depends on your familiarity with energy system modelling. First, all users who are not familiar with the way FlexTool manages data using Spine Toolbox functionalities , should read the page on Spine Toolbox workflow If you are new to energy system modelling , it is probably best to try to build the test system yourself while following the tutorial. This will take time and you will have to look up many data items from the Init database, but it will also force you to learn the concepts. You can also copy-paste data from the Init database to the Input data database when writing the data becomes too tedious. Before you start, it can be a good idea to to check the Essential objects for defining a power/energy system from the beginning of the FlexTool reference page to get an initial understanding of the concepts that will then grow as you learn more. If you have already run the whole workflow, then the Input_data database will be populated and you will need to delete the data before starting to build from scratch. This can be done with the 'purge' tool from the Database Editor menu: in purge , click on both Select entity and value items , and Select scenario items and then purge. If you have experience in using other types of energy system models - or perhaps older versions of FlexTool - it can be sufficient to follow the tutorial while also browsing the Init database using the database editor. Finding the entity classes, entities, and parameter values in the actual database will assist in the learning process. The concept reference page can also be useful. Finally, if you are a really experienced modeller , it can be enough to check the reference section starting from Essential objects for defining a power/energy system . 1st step - a node with no units You should have the FlexTool project open in the Spine Toolbox. Then, open the Input data database by double-clicking it in the Spine Toolbox workflow. The test system is built using alternatives . Alternative is a subset of the system than one can include to a scenario that is optimized by Flextool. For example when adding a wind plant, all the objects and relationships related to only the wind plant should be under their own alternative, so that the wind plant can be included or excluded form the scenario seamlessly. Each step will add a new alternative , and the data it contains, on top of the previous ones. The first alternative will be called west to hold the data for the first node in the model. The alternative is added in the 'Alternative/Scenario tree' widget of the 'Spine Database Editor', see figure below. Next step is to add an object for the first node that will be called west . Right-click on the node object class in the object tree to select 'Add objects'. Use the dialog to add the west node and click ok. See the figures below. Later other objects will need to be added in the same manner - as well as relationships between objects. Then, add parameter data to the newly minted west node : west node represents the demand in a part of the system. First add an inflow parameter with negative values to indicate negative inflow, i.e. demand. The inflow timeseries are given as a map-type parameter where the first column contains the names of the timesteps and the second column contains the inflow parameter value for that timestep. This is tedious to do by hand, so you can also copy-paste this from the init database. There are no electricity generating units and the demand cannot be met by ordinary means. The model will therefore use the upward slack variable and accept the penalty_up cost associated with it. This represents the cost of not fulfilling the demand. Also downward penalty_down is defined although the model is not using it at this stage. Here values of 9000 and 8000 are used respectively. Penalties and slack variables are tools of linear optimization. They ensure that the problem is feasable at all timesteps even when the in-out-balance of the nodes is violated. If no real penalty values are known, one should just use large enough numbers, so that the system won't prefer penalty to energy production. In the results, you can see at which timesteps the penalties are used. The parameter has_balance is related to this and should be set to yes . It forces the node to have a balance on inflow and outflow. If the demand is not fulfilled, balance is forced by the slack variable that will \"create\" the energy with the penalty associated with it. The west node needs to have a parameter called is_active with value yes . This chooses the west node and all its parameters to be sent to the model. All parameters here should be part of the west alternative (column alternative_name) - they will be used whenever a scenario includes the west alternative . The model will also need parameters that define the model structure for time related issues. FlexTool time structure offers a lot of flexibility, but it is also bit complex to learn at first. At this stage not everything needs to be understood - the time structures will be explained in more detail later. First, make a new alternative called init to keep all the model structure related data separate from the data on physical objects. All parameter data that will be added next should go into the init alternative . Then, to get the model to run, you need to create the following objects and relationships: timeline object called y2020 with a map-type parameter timestep_duration that defines the timeline the time series data in the model will need to use. It contains, in the first column, the name of each timestep (e.g. t0001 or 2022-01-01-01 ) and, in the second column, the length of the timestep in hours (e.g. 1.0 ). The timestep names in the previously given inflow time series must match these timestep names - and any other timestep names in later time series. timeblockset object called 2day with a map-type parameter block_duration to define a time block using a timestep name to indicate where the timeblock starts and a number to define the duration of the timeblock in timesteps (e.g. t0001 and 48.0 ). The timeline is larger than the 48, but this way the solver uses only the first 48h. timeblockset 2day and timeline y2020 need to have timeblockset__timeline relationship 2day , y2020 . From the relationship tree right-click on the timeblockset__timeline relationship class to 'Add relationships...'. solve object called y2020_2day_dispatch with a map-type parameter period_timeblockSet to define the timeblockset to be used by each period (in this example: period p2020 in the first column of the map links to the timeblockset object 2day in the second column of the map) with an array-type parameter realized_periods to define the periods that are realised from the solve named by the object (in this example: first column of the array is the index number 1 and the second column contains the period to be realized in the results: p2020 ) with a parameter solve_mode , to be set to single_shot . Finally, the model object needs to be created. It must contain the sequence of solves. In this case flexTool model object contains just one solve y2020_2day_dispatch inside the array-type parameter. Be careful when choosing datatypes! Maps need to be maps not arrays. (In the future, an update is coming to toolbox to make this easier.) The new objects, relationships and parameters have now been staged. Even though it looks like they are in the database, they really are not - they need to be committed first. This can be done from the menu of the Database Editor (there is a commit command) or by pressing ctrl-enter . One should write an informative commit message about the changes that have been made. All commits, and the data they have affected, can be seen later from the history menu item. Interlude - creating a scenario and running the model Even though the model is very simple and will not do anything interesting, it can be executed. It is first necessary to create the scenario to be executed. Scenarios are created from alternatives in the Scenario tree widget of the Database Editor. In the figure below, a scenario called base is created that should contain alternatives west and init in order to have both a node and a model structure included in the model. The new scenario must also be committed , before it can be used. A new scenario should be added after each step in the tutorial process. Once the scenario has been committed to the database, it becomes available in the Spine Toolbox workflow. One can select scenarios to be executed from the arrow that leaves the Input data database. At this point, there will be only the base scenario available and should be selected. There is also a tool filter with FlexTool3 pre-selected. This selection needs to be present when running scenarios (it is used to filter the is_active entities into the scenario). Next, we want to run three tools: Export_to_CSV (that will make input files suitable for FlexTool), FlexTool3 (which is a Python script that calls the FlexTool model generator for each solve) and Import_results (which will take output files from FlexTool and drop their contents to the Results database with a particular alternative name). First, select the three tools (select with left click while ctrl is pressed or draw an area with ctrl pressed, see figure below). Then, press Execute selection from the menu bar. The three items should be executed and if all goes well, then green check marks appear on each of the tool once it has finished. You can explore the outputs of each item by selecting the item and looking at the Console widget window. If the Results database has an error: database not found. Go to the Flextool folder, make a copy of the Results_template.sqlite to the same folder and name it Results.sqlite . After this run the Import_results tool again. It is now possible to explore model results for the base scenario using either the Results database or the Excel file that can be exported by executing the To_Excel exporter tool. When doing that, no scenarios should be selected so that the tool will create one Excel file with data from all the alternatives that are in the results database (which will make more sense once there are more scenario results). The generated Excel file can be found by selecting the To_Excel tool and clicking on the folder icon on top-right of the Link properties widget window. 2nd step - add a coal unit In the second step, a coal unit is added. The first thing is to add a new alternative coal so that all new data added in this step will become part of the coal alternative . Then one needs to add the objects: unit coal_plant node coal_market commodity coal And relationships: unit__inputNode coal_plant, coal_market to indicate that the coal_plant is using inputs from the coal_market unit__outputNode coal_plant, west to indicate that the coal_plant will output electricity to the west node commodity__node coal, coal_market coal_plant needs the following parameters (all set for the coal alternative): efficiency (e.g. 0.4 for 40% efficiency) existing to indicate the existing capacity in the coal_plant (e.g. 500 MW) is_active set to yes to include the coal_plant in the model coal commodity needs just one parameter for price (e.g. 20 \u20ac/MWh of fuel) coal_market node needs to have is_active set to yes All these new parameters should be now part of the coal alternative . To see how the results change due to the coal power plant, make a new scenario coal that has the alternatives init , west and coal . Run the Export_to_CSV , FlexTool3 and Import_results to get the results to the Results database. If you start to get too many result alternatives in the Results database (e.g. if you happen to run the same scenario multiple times), you can delete old ones by removing the unwanted alternatives (right-click on the alternative ) and then committing the database. Interlude - visualizing the system in a graph In Spine Toolbox, it is possible to visualize your system in a graph, which will show all objects, and the relationships between them. To open this visualization mode, open the Input data database. In the top right corner, click on the menu. Select Graph in the View section. You may visualize all objects by selecting root in the Object tree , or choose specifically the objects you want to display by selecting them in the Object tree (maintain ctrl to select multiple objects). 3rd step - add a wind power plant Next, a wind power plant is added. Add a new alternative wind Add objects: unit wind_plant profile wind_profile since wind_plant does not require a commodity, but instead uses a profile to limit the generation to the available wind. Add relationships: unit__node__profile wind_plant, west, wind_profile unit__outputNode wind_plant, west wind_plant needs the following parameters (all set for the wind alternative): conversion_method to choose a method for the conversion process (in this case constant_efficiency ) efficiency for wind_plant should be set to 1 existing capacity can be set to 1000 MW is_active set to yes to include the wind_plant in the model wind_profile needs the the parameter profile with a map of values where each time step gets the maximum available capacity factor for that time step (see figure). Again, you can copy this from the init database. wind_plant, west, wind_profile relationship needs a parameter profile_method with the choice upper_limit selected. This means that the wind_plant must generate at or below its capacity factor. You can now create a new scenario wind , that has the alternatives init , west , coal and wind . Remember to commit , execute and have a look at the results (there should be no more penalty values used, since the coal and wind plant can together meet the demand in all hours). 4th step - add a network A network alternative introduces two new nodes ( east and north ) three new connections between nodes ( east_north , west_east and west_north ). The new nodes are kept simple: they have a is_active parameter set to yes they have a has_balance parameter set to yes (to force the node to maintain an energy balance) they have a constant negative inflow (i.e. demand) penalty values for violating their energy balance The three connections have the following parameters: they have a is_active parameter set to yes they have a existing parameter to indicate the existing interconnection capacity between the nodes they have a efficiency parameter (e.g. 0.9 for 90% efficiency). It is also necessary to create the relationships connection__node__node for east_north | east | north , west_north | west | north and west_east | west | east . The north node has the lowest upward penalty, so the model will prefer to use that whenever the coal and wind units cannot meet all the demand. Sometimes the existing capacity of the new connections will not be sufficient to carry all the needed power, since both generators are producing to the west node . Commit , execute and explore. 5th step - add a reserve Create a new alternative reserve. Reserve requirement is defined for a group of nodes as the reserve can be set to be dependent on the loads of the nodes (this tutorial uses a constant reserve). Therefore, the first step is to add a new group called electricity with west , east and north as its members using the group__node relationship class. Then, a new reserve category called primary is added to the reserve object class. Finally, if it does not exist yet, add a new object `UpDown', called up to define the reserve mode. A relationship between primary--up--electricity in the reserve__upDown__group class allows to define the reserve parameters reserve_method , reservation (i.e. the amount of reserve) and penalty_reserve (i.e. the penalty cost in case of lack of reserve). In this case the reserve requirement will be a constant 10MW even though the reserve_method is timeseries_only . The other alternative is dynamic reserves where the model calculates the reserve requirement from generation and loads according to user defined factors ( increase_reserve_ratio ). Parameters from the reserve__upDown__unit__node class should be used to define how different units can contribute to different reserves. Parameter max_share says how large share of the total capacity of the timestep (existing * efficiency (profile)) of the unit can contribute to this reserve category (e.g. coal_plant , in this example, has ramping restrictions and can only provide 1% of it's capacity to this upward primary reserve.) Meanwhile, parameter reliability affects what portion of the reserved capacity actually contributes to the reserve (e.g. in this contrived example, wind_plant* must have extra capacity of 20 MW to provide 10 MW of reserve). Create the scenario, commit , execute and explore how the reserve requirements affect the model results. More functionality Adding a storage unit (battery) init - west - wind - battery In the Init SQLite database, there is a scenario wind_battery - the wind_plant alone is not able to meet the load in all conditions, but the battery will help it to improve the situation. In FlexTool, only nodes can have storage. This means that existing capacity and all investment parameters for nodes refer to the amount of storage the node can have. In this example, a battery node is established to describe the storage properties of the battery (e.g. existing capacity and self_discharge_loss in each hour). Battery also needs charging and discharging capabilities. These could be presented either with a connection or by having a charging unit and a discharging unit . In here, we are using a connection called batter_inverter , since its easier to prevent simultaneous charging and discharging that way (although, in a linear model, this cannot be fully prevented since that requires an integer variable). Please note that the efficiency parameter of the connection applies to both directions, so the round-trip efficiency will be efficiency squared. The transfer_method can be used by all types of connections, but in this case it is best to choose regular , which tries to avoid simultaneous charging and discharing, but can still do it when the model needs to dissipate energy. exact method would prevent that, but it would require integer variables and make the storage computationally much more expensive. Model leakage will be reported in the results (forthcoming). Adding battery investment capabilities init - west - wind - battery - battery_invest To make the wind_battery scenario more interesting, an option to invest in battery and battery_inverter is added. It also demonstrates how FlexTool can have more complicated constraints that the user defines through data. First, the investment parameters need to be included both for the battery_inverter and battery objects: invest_method - the modeller needs to choose between only_invest , only_retire , invest_and_retire or not_allowed invest_cost - overnight investment cost new capacity [currency/kW] for the battery_inverter and [currency/kWh] for the battery . Other one can be left empty or zero, since they will be tied together in the next phase. Here we will assume a fixed relation between kW and kWh for this battery technology, but for example flow batteries could have separate investments for storage and charging capacities. invest_max_total - maximum investment (power [MW] or energy [MWh]) to the virtual capacity of a group of units or to the storage capacity of a group of nodes. This should not be empty or zero, since then the model cannot invest in the technology. interest_rate - an interest rate [e.g. 0.05 means 5%] for the technology that is sufficient to cover capital costs assuming that the economic lifetime equals the technical lifetime lifetime - technical lifetime of the technology to calculate investment annuity (together with interest rate) Second, a new constraint needs to be created that ties together the storage capacity of the battery and the charging/discharging capacity of the battery_inverter . A new constraint object battery_tie_kW_kWh is created and it is given parameters constant , is_active and sense . Constant could be left out, since it is zero, but is_active must be defined in order to include the constraint in the battery_invest alternative . The sense of the constraint must be equal to enforce the kw/kWh relation. Third, both battery_inverter and battery need a coefficient to tell the model how they relate to each other. The equation has the capacity variables on the left side of the equation and the constant on the right side. sum_i(`constraint_capacity_coefficient` * `invested_capacity`) = `constant` where i is any unit, connection or node that is part of the constraint When the constraint_capacity_coefficient for battery is set at 1 and for the battery_inverter at -8, then the equation will force battery_inverter capacity to be 8 times smaller than the battery capacity . The negative term can be seen to move to the right side of the equation, which yields: 1 x *battery* = 8 x *battery_inverter*, which can be true only if *battery_inverter* is 1/8 of *battery* constraint_capacity_coefficient is not a parameter with a single value, but a map type parameter (index: constraint name, value: coefficient). It allows the object to participate in multiple constraints. Finally, FlexTool can actually mix three different types of constraint coefficients: constraint_capacity_coefficient , constraint_state_coefficient and constraint_flow_coefficient allowing the user to create custom constraints between any types of objects in the model for the main variables in the model ( flow , state as well as invest and divest ). So, the equation above is in full form: + sum_i [constraint_capacity_coefficient(i) * invested_capacity] where i contains [node, unit, connection] belonging to the constraint + sum_j [constraint_flow_coefficient(j) * invested_capacity] where j contains [unit--node, connection--node] belonging to the constraint + sum_k [constraint_state_coefficient(k) * invested_capacity] where k contains [node] belonging to the constraint = constant Combined heat and power (CHP) example init - west - coal_chp - heat This CHP plant is an another example where the user defined constraint (see the last equation in the previous example) is used to achieve desired behaviour. In a backpressure CHP, heat and power outputs are fixed - increase one of them, and you must also increase the other. In an extraction CHP plant the relation is more complicated - there is an allowed operating area between heat and power. Both can be depicted in FlexTool, but here a backpressure example is given. An extraction plant would require two or more greater_than and/or lesser_than constraints to define an operating area. First, a new heat node is added and it is given the necessary parameters. Then the coal_chp unit is made with a high efficiency parameter, since CHP units convert fuel energy to power and heat at high overall rates. In FlexTool, efficiency is a property of the unit - it demarcates at what rate the sum of inputs is converted to the sum of outputs. However, without any additional constraints, the unit is free to choose in what proportion to use inputs and in which proportion to use outputs. In units with only one input and output, this freedom does not exist, but in here, the coal_chp needs to be constrained as otherwise the unit could produce electricity at 90% efficiency, which is not feasible. This is done by adding a new constraint coal_chp_fix where the heat and power co-efficients are fixed. You need to create the two relationships unit__outputNode , for coal_chp--heat and coal_chp--west . As can be seen in the bottom part of the figure below, the constraint_flow_coefficient parameter for the coal_chp--heat and coal_chp--west is set as a map value where the constraint name matches with the coal_chp_fix constraint object name. The values are set so that the constraint equation forces the heat output to be twice as large as the electricity output. Again, the negative value moves the other variable to the right side of the equality, creating this: 1 x *electricity* = 0.5 x *heat*, which is true only if *heat* is 2 x *electricity* Minimum load example init - west - coal - coal_min_load The next example is simpler. It adds a minimum load behavior to the coal_plant unit . Minimum load requires that the unit must have an online variable in addition to flow variables and therefore a startup_method needs to be defined and an optional startup_cost can be given. The options are no_startup , linear and binary . binary would require an integer variable so linear is chosen. However, this means that the unit can startup partially. The minimum online will still apply, but it is the minimum of the online capacity in any given moment ( flow >= min_load x capacity_online ). The online variable also allows to change the efficiency of the plant between the minimum and full loads. An unit with a part-load efficiency will obey the following equation: + sum_i[ input(i) * input_coefficient(i) ] = + sum_o[ output(o) * output_coefficient(o) ] * slope + online * section where slope = 1 / efficiency - section and section = 1 / efficiency - ( 1 / efficiency - 1 / efficiency_at_min_load) / ( 1 - efficiency_at_min_load ) By default, input_coefficient and output_coefficient are 1, but if there is a need to tweak their relative contributions, these coefficients allow to do so (e.g. a coal plant might have lower efficieny when using lignite than when using brown coal). Adding CO2 emissions and costs init - west - coal - co2 Carbon dioxide emissions are added to FlexTool by associating relevant commodities (e.g. coal ) with a co2_content parameter (CO2 content per MWh of energy contained in the fuel). To set a price for the CO2, the nodes that use those commodities will need to be linked to a group of nodes that set the co2_price (currency / CO2 ton). Therefore, in addition to what is visible in the figure below, a relationship co2_price--coal_market must be established so that the model knows to point the CO2_price to the commodity used from the coal_market node based on the co2_content of the coal commodity . Full year model init - west - fullYear So far the model has been using only two days to keep it fast to run. This example extends the model horizon to a full year. To do so, a new solve object y2020_fullYear_dispatch is added. Each solve object needs to know what periods it will contain and what periods it will realize (print out results). solve_mode does not do anything at present, but will be used when FlexTool can be set to do automatic rolling window optimization (at present, it needs to be set manually using multiple solves). The key difference here is that the period_timeblockSet parameter points the p2020 period to a timeblockSet definition that covers the full year instead of the two days used before. A system with coal, wind, network, battery and CO2 over a full year init - west - coal - wind - network - battery - co2 - fullYear This example shows a system where many of the previous examples have been put into one model and run for one year. The graph below shows the physical objects in the example. Representative periods init - west - wind - battery - battery_invest - 5weeks When using the model for investment decisions, the model can often become too large to solve. Representative periods can be used to take a sample of a full year that tries to depict the dynamics in a reasonable manner. In FlexTool, this is done with the block_duration parameter. It needs to contain the starting timestep and the duration of each period as shown in figure below. Multi-year model init - west - wind - coal - coal_invest - 5weeks - multi-year A multi-year model is constructed from multiple periods, each presenting one year. In the example case, each year is otherwise the same, but the demand is increasing in the west node . The inflow time series are scaled to match the value in annual_flow . The model is using the inflow_method scale_to_annual in order to achieve this (default is use_original that would not perform scaling). There should also be a discount_rate parameter set for the model object flexTool if something else than the model default of 5% (0.05 value) is to be used. A multi-year model could be solved at one go or by rolling through several solves where each solve has a foresight horizon and a realisation horizon as can be seen from the figure below. In this example, the model rolls through several solves and therefore, in the figure above, the model object flexTool has four values in the solves array. Each value respresents one solve and it's position in the sequence of solves. Next figure shows the values needed to define one solve (out of the four solves in the example). All of these need to be repeated for each solve in the model. years_represented parameter is used by the model to calculate the discounting factors for the periods in the model (often future years). It should state the number of years each period will be representing. For example, a period for 2025 could represent the years 2025-2029 if its years_represented is set to 5. Any investments would be take place at the start of 2025 and discounted to the beginning of 2025, but the operational costs would accrue from each year in 2025-2029 each with a different discounting factor (decreasing based on interest rate). invest_periods parameter says in which periods the model is allowed to make investments realized_periods parameter states the periods that will be realized in this solve (results output) period_timeblockset defines the set of representative 'periods' (timeblocks in FlexTool) to be used in each FlexTool period . Discount calculations Each asset that can be invested in should have invest_cost , lifetime and interest_rate parameters set and could have an optional fixed_cost . These are used to calculate the annuity of the investment. Annuity is used to annualize the investment cost, since FlexTool scales all costs (operational, investment and fixed) to annual level in order to make them comparable. Annuity is calculated as follows: invest_cost * interest_rate / { 1 - [ 1 / ( 1 + interest_rate ) ] ^ lifetime } + fixed_cost The next step is to consider discounting - future is valued less than the present. There is a model-wide assumption for the discount_rate . By default it is 0.05 (i.e. 5%), but it can be changed through the discount_rate parameter set for the flexTool model object. Discount factor for every period in the model is calculated from the discount_rate using the years_represented parameter of each solve , which how many years the period represents. Values for years_represented are used to calculate how many years_from_solve_start each year is. The formula is: [ 1 / ( 1 + discount_rate ) ] ^ years_from_solve_start Operational costs are also discounted using the same discount_rate . However, with operational costs it is assumed that they take place on average at the middle of the year whereas investment costs are assumed to take place at the beginning of the year (they are available for the whole year). These can be tweaked with the discount_offset_investments and discount_offset_operations parameters (given in years). Please note that given this formulation, invest_cost should be the overnight built cost (as is typical in energy system modelling, the model does not assume any construction time - the financing costs of the construction period need to be included in your cost assumptions). The model has a model horizon based on the years_represented parameters. The model will not include discounted investment annuities after the model horizon (in other words, the investments are 'returned' at the end of the model horizon). Naturally also operational costs are included only until the end of the model horizon. Finally, the retirements work similar to investments using the same discount_rate and interest_rate parameters but with salvage_value as the benefit from retiring the unit.","title":"Tutorial"},{"location":"tutorial/#irena-flextool-tutorial","text":"The instructions for installing IRENA FlexTool are here . This user guide will build a small system step-by-step. It assumes you will be using Spine Toolbox as the front-end. If you are using the IRENA FlexTool web-interface, the instructions still apply, but the example figures in this tutorial will not be as helpful. IRENA FlexTool concepts are explained in more depth at this page . Video tutorial for Building a small test system can be watched here . The small system to be built is also directly available in the FlexTool repository ( Init SQLite database) and can be opened with the Spine Toolbox database editor. The default workflow for IRENA FlexTool executes the scenarios from the Input data database (and not from the Init SQLite database). The Input data database is empty by default. Therefore, if you want to use directly the contents of the Init database (instead of building the small system step-by-step), you need to copy them to the Input data database before running the scenarios in this tutorial. To copy the data, you need to execute the Initialize workflow item: select the item, press Execute selection from the toolbar. It is not advised to run the whole workflow, ( Execute project ) since it will copy data from two sources: the Excel based input data file and the Init database and this will create two sets of data in the Input data database. More information on how to set-up and use the Spine Toolbox front-end in here . If not done already, in the flextool folder make a copy of the Results_template.sqlite and rename it Results.sqlite. Remark: in case you had already populated the Input data database, you need to delete the data before importing from Init SQLite database. This can be done with the 'purge' tool from the Database Editor menu: in purge , click on both Select entity and value items , and Select scenario items and then purge. Building a small test system 1st step - a node with no units 2nd step - add a coal unit 3rd step - add a wind power plant 4th step - add a network 5th step - add a reserve More functionality Adding a storage unit (battery) Adding battery investment capabilities Minimum load example Adding CO2 emissions and costs Full year model A system with coal, wind, network, battery and CO2 over a full year Representative periods Multi-year model Discount calculations","title":"IRENA FlexTool tutorial"},{"location":"tutorial/#building-a-small-test-system","text":"This tutorial can be used in couple of different ways - the best way depends on your familiarity with energy system modelling. First, all users who are not familiar with the way FlexTool manages data using Spine Toolbox functionalities , should read the page on Spine Toolbox workflow If you are new to energy system modelling , it is probably best to try to build the test system yourself while following the tutorial. This will take time and you will have to look up many data items from the Init database, but it will also force you to learn the concepts. You can also copy-paste data from the Init database to the Input data database when writing the data becomes too tedious. Before you start, it can be a good idea to to check the Essential objects for defining a power/energy system from the beginning of the FlexTool reference page to get an initial understanding of the concepts that will then grow as you learn more. If you have already run the whole workflow, then the Input_data database will be populated and you will need to delete the data before starting to build from scratch. This can be done with the 'purge' tool from the Database Editor menu: in purge , click on both Select entity and value items , and Select scenario items and then purge. If you have experience in using other types of energy system models - or perhaps older versions of FlexTool - it can be sufficient to follow the tutorial while also browsing the Init database using the database editor. Finding the entity classes, entities, and parameter values in the actual database will assist in the learning process. The concept reference page can also be useful. Finally, if you are a really experienced modeller , it can be enough to check the reference section starting from Essential objects for defining a power/energy system .","title":"Building a small test system"},{"location":"tutorial/#1st-step-a-node-with-no-units","text":"You should have the FlexTool project open in the Spine Toolbox. Then, open the Input data database by double-clicking it in the Spine Toolbox workflow. The test system is built using alternatives . Alternative is a subset of the system than one can include to a scenario that is optimized by Flextool. For example when adding a wind plant, all the objects and relationships related to only the wind plant should be under their own alternative, so that the wind plant can be included or excluded form the scenario seamlessly. Each step will add a new alternative , and the data it contains, on top of the previous ones. The first alternative will be called west to hold the data for the first node in the model. The alternative is added in the 'Alternative/Scenario tree' widget of the 'Spine Database Editor', see figure below. Next step is to add an object for the first node that will be called west . Right-click on the node object class in the object tree to select 'Add objects'. Use the dialog to add the west node and click ok. See the figures below. Later other objects will need to be added in the same manner - as well as relationships between objects. Then, add parameter data to the newly minted west node : west node represents the demand in a part of the system. First add an inflow parameter with negative values to indicate negative inflow, i.e. demand. The inflow timeseries are given as a map-type parameter where the first column contains the names of the timesteps and the second column contains the inflow parameter value for that timestep. This is tedious to do by hand, so you can also copy-paste this from the init database. There are no electricity generating units and the demand cannot be met by ordinary means. The model will therefore use the upward slack variable and accept the penalty_up cost associated with it. This represents the cost of not fulfilling the demand. Also downward penalty_down is defined although the model is not using it at this stage. Here values of 9000 and 8000 are used respectively. Penalties and slack variables are tools of linear optimization. They ensure that the problem is feasable at all timesteps even when the in-out-balance of the nodes is violated. If no real penalty values are known, one should just use large enough numbers, so that the system won't prefer penalty to energy production. In the results, you can see at which timesteps the penalties are used. The parameter has_balance is related to this and should be set to yes . It forces the node to have a balance on inflow and outflow. If the demand is not fulfilled, balance is forced by the slack variable that will \"create\" the energy with the penalty associated with it. The west node needs to have a parameter called is_active with value yes . This chooses the west node and all its parameters to be sent to the model. All parameters here should be part of the west alternative (column alternative_name) - they will be used whenever a scenario includes the west alternative . The model will also need parameters that define the model structure for time related issues. FlexTool time structure offers a lot of flexibility, but it is also bit complex to learn at first. At this stage not everything needs to be understood - the time structures will be explained in more detail later. First, make a new alternative called init to keep all the model structure related data separate from the data on physical objects. All parameter data that will be added next should go into the init alternative . Then, to get the model to run, you need to create the following objects and relationships: timeline object called y2020 with a map-type parameter timestep_duration that defines the timeline the time series data in the model will need to use. It contains, in the first column, the name of each timestep (e.g. t0001 or 2022-01-01-01 ) and, in the second column, the length of the timestep in hours (e.g. 1.0 ). The timestep names in the previously given inflow time series must match these timestep names - and any other timestep names in later time series. timeblockset object called 2day with a map-type parameter block_duration to define a time block using a timestep name to indicate where the timeblock starts and a number to define the duration of the timeblock in timesteps (e.g. t0001 and 48.0 ). The timeline is larger than the 48, but this way the solver uses only the first 48h. timeblockset 2day and timeline y2020 need to have timeblockset__timeline relationship 2day , y2020 . From the relationship tree right-click on the timeblockset__timeline relationship class to 'Add relationships...'. solve object called y2020_2day_dispatch with a map-type parameter period_timeblockSet to define the timeblockset to be used by each period (in this example: period p2020 in the first column of the map links to the timeblockset object 2day in the second column of the map) with an array-type parameter realized_periods to define the periods that are realised from the solve named by the object (in this example: first column of the array is the index number 1 and the second column contains the period to be realized in the results: p2020 ) with a parameter solve_mode , to be set to single_shot . Finally, the model object needs to be created. It must contain the sequence of solves. In this case flexTool model object contains just one solve y2020_2day_dispatch inside the array-type parameter. Be careful when choosing datatypes! Maps need to be maps not arrays. (In the future, an update is coming to toolbox to make this easier.) The new objects, relationships and parameters have now been staged. Even though it looks like they are in the database, they really are not - they need to be committed first. This can be done from the menu of the Database Editor (there is a commit command) or by pressing ctrl-enter . One should write an informative commit message about the changes that have been made. All commits, and the data they have affected, can be seen later from the history menu item.","title":"1st step - a node with no units"},{"location":"tutorial/#interlude-creating-a-scenario-and-running-the-model","text":"Even though the model is very simple and will not do anything interesting, it can be executed. It is first necessary to create the scenario to be executed. Scenarios are created from alternatives in the Scenario tree widget of the Database Editor. In the figure below, a scenario called base is created that should contain alternatives west and init in order to have both a node and a model structure included in the model. The new scenario must also be committed , before it can be used. A new scenario should be added after each step in the tutorial process. Once the scenario has been committed to the database, it becomes available in the Spine Toolbox workflow. One can select scenarios to be executed from the arrow that leaves the Input data database. At this point, there will be only the base scenario available and should be selected. There is also a tool filter with FlexTool3 pre-selected. This selection needs to be present when running scenarios (it is used to filter the is_active entities into the scenario). Next, we want to run three tools: Export_to_CSV (that will make input files suitable for FlexTool), FlexTool3 (which is a Python script that calls the FlexTool model generator for each solve) and Import_results (which will take output files from FlexTool and drop their contents to the Results database with a particular alternative name). First, select the three tools (select with left click while ctrl is pressed or draw an area with ctrl pressed, see figure below). Then, press Execute selection from the menu bar. The three items should be executed and if all goes well, then green check marks appear on each of the tool once it has finished. You can explore the outputs of each item by selecting the item and looking at the Console widget window. If the Results database has an error: database not found. Go to the Flextool folder, make a copy of the Results_template.sqlite to the same folder and name it Results.sqlite . After this run the Import_results tool again. It is now possible to explore model results for the base scenario using either the Results database or the Excel file that can be exported by executing the To_Excel exporter tool. When doing that, no scenarios should be selected so that the tool will create one Excel file with data from all the alternatives that are in the results database (which will make more sense once there are more scenario results). The generated Excel file can be found by selecting the To_Excel tool and clicking on the folder icon on top-right of the Link properties widget window.","title":"Interlude - creating a scenario and running the model"},{"location":"tutorial/#2nd-step-add-a-coal-unit","text":"In the second step, a coal unit is added. The first thing is to add a new alternative coal so that all new data added in this step will become part of the coal alternative . Then one needs to add the objects: unit coal_plant node coal_market commodity coal And relationships: unit__inputNode coal_plant, coal_market to indicate that the coal_plant is using inputs from the coal_market unit__outputNode coal_plant, west to indicate that the coal_plant will output electricity to the west node commodity__node coal, coal_market coal_plant needs the following parameters (all set for the coal alternative): efficiency (e.g. 0.4 for 40% efficiency) existing to indicate the existing capacity in the coal_plant (e.g. 500 MW) is_active set to yes to include the coal_plant in the model coal commodity needs just one parameter for price (e.g. 20 \u20ac/MWh of fuel) coal_market node needs to have is_active set to yes All these new parameters should be now part of the coal alternative . To see how the results change due to the coal power plant, make a new scenario coal that has the alternatives init , west and coal . Run the Export_to_CSV , FlexTool3 and Import_results to get the results to the Results database. If you start to get too many result alternatives in the Results database (e.g. if you happen to run the same scenario multiple times), you can delete old ones by removing the unwanted alternatives (right-click on the alternative ) and then committing the database.","title":"2nd step - add a coal unit"},{"location":"tutorial/#interlude-visualizing-the-system-in-a-graph","text":"In Spine Toolbox, it is possible to visualize your system in a graph, which will show all objects, and the relationships between them. To open this visualization mode, open the Input data database. In the top right corner, click on the menu. Select Graph in the View section. You may visualize all objects by selecting root in the Object tree , or choose specifically the objects you want to display by selecting them in the Object tree (maintain ctrl to select multiple objects).","title":"Interlude - visualizing the system in a graph"},{"location":"tutorial/#3rd-step-add-a-wind-power-plant","text":"Next, a wind power plant is added. Add a new alternative wind Add objects: unit wind_plant profile wind_profile since wind_plant does not require a commodity, but instead uses a profile to limit the generation to the available wind. Add relationships: unit__node__profile wind_plant, west, wind_profile unit__outputNode wind_plant, west wind_plant needs the following parameters (all set for the wind alternative): conversion_method to choose a method for the conversion process (in this case constant_efficiency ) efficiency for wind_plant should be set to 1 existing capacity can be set to 1000 MW is_active set to yes to include the wind_plant in the model wind_profile needs the the parameter profile with a map of values where each time step gets the maximum available capacity factor for that time step (see figure). Again, you can copy this from the init database. wind_plant, west, wind_profile relationship needs a parameter profile_method with the choice upper_limit selected. This means that the wind_plant must generate at or below its capacity factor. You can now create a new scenario wind , that has the alternatives init , west , coal and wind . Remember to commit , execute and have a look at the results (there should be no more penalty values used, since the coal and wind plant can together meet the demand in all hours).","title":"3rd step - add a wind power plant"},{"location":"tutorial/#4th-step-add-a-network","text":"A network alternative introduces two new nodes ( east and north ) three new connections between nodes ( east_north , west_east and west_north ). The new nodes are kept simple: they have a is_active parameter set to yes they have a has_balance parameter set to yes (to force the node to maintain an energy balance) they have a constant negative inflow (i.e. demand) penalty values for violating their energy balance The three connections have the following parameters: they have a is_active parameter set to yes they have a existing parameter to indicate the existing interconnection capacity between the nodes they have a efficiency parameter (e.g. 0.9 for 90% efficiency). It is also necessary to create the relationships connection__node__node for east_north | east | north , west_north | west | north and west_east | west | east . The north node has the lowest upward penalty, so the model will prefer to use that whenever the coal and wind units cannot meet all the demand. Sometimes the existing capacity of the new connections will not be sufficient to carry all the needed power, since both generators are producing to the west node . Commit , execute and explore.","title":"4th step - add a network"},{"location":"tutorial/#5th-step-add-a-reserve","text":"Create a new alternative reserve. Reserve requirement is defined for a group of nodes as the reserve can be set to be dependent on the loads of the nodes (this tutorial uses a constant reserve). Therefore, the first step is to add a new group called electricity with west , east and north as its members using the group__node relationship class. Then, a new reserve category called primary is added to the reserve object class. Finally, if it does not exist yet, add a new object `UpDown', called up to define the reserve mode. A relationship between primary--up--electricity in the reserve__upDown__group class allows to define the reserve parameters reserve_method , reservation (i.e. the amount of reserve) and penalty_reserve (i.e. the penalty cost in case of lack of reserve). In this case the reserve requirement will be a constant 10MW even though the reserve_method is timeseries_only . The other alternative is dynamic reserves where the model calculates the reserve requirement from generation and loads according to user defined factors ( increase_reserve_ratio ). Parameters from the reserve__upDown__unit__node class should be used to define how different units can contribute to different reserves. Parameter max_share says how large share of the total capacity of the timestep (existing * efficiency (profile)) of the unit can contribute to this reserve category (e.g. coal_plant , in this example, has ramping restrictions and can only provide 1% of it's capacity to this upward primary reserve.) Meanwhile, parameter reliability affects what portion of the reserved capacity actually contributes to the reserve (e.g. in this contrived example, wind_plant* must have extra capacity of 20 MW to provide 10 MW of reserve). Create the scenario, commit , execute and explore how the reserve requirements affect the model results.","title":"5th step - add a reserve"},{"location":"tutorial/#more-functionality","text":"","title":"More functionality"},{"location":"tutorial/#adding-a-storage-unit-battery","text":"init - west - wind - battery In the Init SQLite database, there is a scenario wind_battery - the wind_plant alone is not able to meet the load in all conditions, but the battery will help it to improve the situation. In FlexTool, only nodes can have storage. This means that existing capacity and all investment parameters for nodes refer to the amount of storage the node can have. In this example, a battery node is established to describe the storage properties of the battery (e.g. existing capacity and self_discharge_loss in each hour). Battery also needs charging and discharging capabilities. These could be presented either with a connection or by having a charging unit and a discharging unit . In here, we are using a connection called batter_inverter , since its easier to prevent simultaneous charging and discharging that way (although, in a linear model, this cannot be fully prevented since that requires an integer variable). Please note that the efficiency parameter of the connection applies to both directions, so the round-trip efficiency will be efficiency squared. The transfer_method can be used by all types of connections, but in this case it is best to choose regular , which tries to avoid simultaneous charging and discharing, but can still do it when the model needs to dissipate energy. exact method would prevent that, but it would require integer variables and make the storage computationally much more expensive. Model leakage will be reported in the results (forthcoming).","title":"Adding a storage unit (battery)"},{"location":"tutorial/#adding-battery-investment-capabilities","text":"init - west - wind - battery - battery_invest To make the wind_battery scenario more interesting, an option to invest in battery and battery_inverter is added. It also demonstrates how FlexTool can have more complicated constraints that the user defines through data. First, the investment parameters need to be included both for the battery_inverter and battery objects: invest_method - the modeller needs to choose between only_invest , only_retire , invest_and_retire or not_allowed invest_cost - overnight investment cost new capacity [currency/kW] for the battery_inverter and [currency/kWh] for the battery . Other one can be left empty or zero, since they will be tied together in the next phase. Here we will assume a fixed relation between kW and kWh for this battery technology, but for example flow batteries could have separate investments for storage and charging capacities. invest_max_total - maximum investment (power [MW] or energy [MWh]) to the virtual capacity of a group of units or to the storage capacity of a group of nodes. This should not be empty or zero, since then the model cannot invest in the technology. interest_rate - an interest rate [e.g. 0.05 means 5%] for the technology that is sufficient to cover capital costs assuming that the economic lifetime equals the technical lifetime lifetime - technical lifetime of the technology to calculate investment annuity (together with interest rate) Second, a new constraint needs to be created that ties together the storage capacity of the battery and the charging/discharging capacity of the battery_inverter . A new constraint object battery_tie_kW_kWh is created and it is given parameters constant , is_active and sense . Constant could be left out, since it is zero, but is_active must be defined in order to include the constraint in the battery_invest alternative . The sense of the constraint must be equal to enforce the kw/kWh relation. Third, both battery_inverter and battery need a coefficient to tell the model how they relate to each other. The equation has the capacity variables on the left side of the equation and the constant on the right side. sum_i(`constraint_capacity_coefficient` * `invested_capacity`) = `constant` where i is any unit, connection or node that is part of the constraint When the constraint_capacity_coefficient for battery is set at 1 and for the battery_inverter at -8, then the equation will force battery_inverter capacity to be 8 times smaller than the battery capacity . The negative term can be seen to move to the right side of the equation, which yields: 1 x *battery* = 8 x *battery_inverter*, which can be true only if *battery_inverter* is 1/8 of *battery* constraint_capacity_coefficient is not a parameter with a single value, but a map type parameter (index: constraint name, value: coefficient). It allows the object to participate in multiple constraints. Finally, FlexTool can actually mix three different types of constraint coefficients: constraint_capacity_coefficient , constraint_state_coefficient and constraint_flow_coefficient allowing the user to create custom constraints between any types of objects in the model for the main variables in the model ( flow , state as well as invest and divest ). So, the equation above is in full form: + sum_i [constraint_capacity_coefficient(i) * invested_capacity] where i contains [node, unit, connection] belonging to the constraint + sum_j [constraint_flow_coefficient(j) * invested_capacity] where j contains [unit--node, connection--node] belonging to the constraint + sum_k [constraint_state_coefficient(k) * invested_capacity] where k contains [node] belonging to the constraint = constant","title":"Adding battery investment capabilities"},{"location":"tutorial/#combined-heat-and-power-chp-example","text":"init - west - coal_chp - heat This CHP plant is an another example where the user defined constraint (see the last equation in the previous example) is used to achieve desired behaviour. In a backpressure CHP, heat and power outputs are fixed - increase one of them, and you must also increase the other. In an extraction CHP plant the relation is more complicated - there is an allowed operating area between heat and power. Both can be depicted in FlexTool, but here a backpressure example is given. An extraction plant would require two or more greater_than and/or lesser_than constraints to define an operating area. First, a new heat node is added and it is given the necessary parameters. Then the coal_chp unit is made with a high efficiency parameter, since CHP units convert fuel energy to power and heat at high overall rates. In FlexTool, efficiency is a property of the unit - it demarcates at what rate the sum of inputs is converted to the sum of outputs. However, without any additional constraints, the unit is free to choose in what proportion to use inputs and in which proportion to use outputs. In units with only one input and output, this freedom does not exist, but in here, the coal_chp needs to be constrained as otherwise the unit could produce electricity at 90% efficiency, which is not feasible. This is done by adding a new constraint coal_chp_fix where the heat and power co-efficients are fixed. You need to create the two relationships unit__outputNode , for coal_chp--heat and coal_chp--west . As can be seen in the bottom part of the figure below, the constraint_flow_coefficient parameter for the coal_chp--heat and coal_chp--west is set as a map value where the constraint name matches with the coal_chp_fix constraint object name. The values are set so that the constraint equation forces the heat output to be twice as large as the electricity output. Again, the negative value moves the other variable to the right side of the equality, creating this: 1 x *electricity* = 0.5 x *heat*, which is true only if *heat* is 2 x *electricity*","title":"Combined heat and power (CHP) example"},{"location":"tutorial/#minimum-load-example","text":"init - west - coal - coal_min_load The next example is simpler. It adds a minimum load behavior to the coal_plant unit . Minimum load requires that the unit must have an online variable in addition to flow variables and therefore a startup_method needs to be defined and an optional startup_cost can be given. The options are no_startup , linear and binary . binary would require an integer variable so linear is chosen. However, this means that the unit can startup partially. The minimum online will still apply, but it is the minimum of the online capacity in any given moment ( flow >= min_load x capacity_online ). The online variable also allows to change the efficiency of the plant between the minimum and full loads. An unit with a part-load efficiency will obey the following equation: + sum_i[ input(i) * input_coefficient(i) ] = + sum_o[ output(o) * output_coefficient(o) ] * slope + online * section where slope = 1 / efficiency - section and section = 1 / efficiency - ( 1 / efficiency - 1 / efficiency_at_min_load) / ( 1 - efficiency_at_min_load ) By default, input_coefficient and output_coefficient are 1, but if there is a need to tweak their relative contributions, these coefficients allow to do so (e.g. a coal plant might have lower efficieny when using lignite than when using brown coal).","title":"Minimum load example"},{"location":"tutorial/#adding-co2-emissions-and-costs","text":"init - west - coal - co2 Carbon dioxide emissions are added to FlexTool by associating relevant commodities (e.g. coal ) with a co2_content parameter (CO2 content per MWh of energy contained in the fuel). To set a price for the CO2, the nodes that use those commodities will need to be linked to a group of nodes that set the co2_price (currency / CO2 ton). Therefore, in addition to what is visible in the figure below, a relationship co2_price--coal_market must be established so that the model knows to point the CO2_price to the commodity used from the coal_market node based on the co2_content of the coal commodity .","title":"Adding CO2 emissions and costs"},{"location":"tutorial/#full-year-model","text":"init - west - fullYear So far the model has been using only two days to keep it fast to run. This example extends the model horizon to a full year. To do so, a new solve object y2020_fullYear_dispatch is added. Each solve object needs to know what periods it will contain and what periods it will realize (print out results). solve_mode does not do anything at present, but will be used when FlexTool can be set to do automatic rolling window optimization (at present, it needs to be set manually using multiple solves). The key difference here is that the period_timeblockSet parameter points the p2020 period to a timeblockSet definition that covers the full year instead of the two days used before.","title":"Full year model"},{"location":"tutorial/#a-system-with-coal-wind-network-battery-and-co2-over-a-full-year","text":"init - west - coal - wind - network - battery - co2 - fullYear This example shows a system where many of the previous examples have been put into one model and run for one year. The graph below shows the physical objects in the example.","title":"A system with coal, wind, network, battery and CO2 over a full year"},{"location":"tutorial/#representative-periods","text":"init - west - wind - battery - battery_invest - 5weeks When using the model for investment decisions, the model can often become too large to solve. Representative periods can be used to take a sample of a full year that tries to depict the dynamics in a reasonable manner. In FlexTool, this is done with the block_duration parameter. It needs to contain the starting timestep and the duration of each period as shown in figure below.","title":"Representative periods"},{"location":"tutorial/#multi-year-model","text":"init - west - wind - coal - coal_invest - 5weeks - multi-year A multi-year model is constructed from multiple periods, each presenting one year. In the example case, each year is otherwise the same, but the demand is increasing in the west node . The inflow time series are scaled to match the value in annual_flow . The model is using the inflow_method scale_to_annual in order to achieve this (default is use_original that would not perform scaling). There should also be a discount_rate parameter set for the model object flexTool if something else than the model default of 5% (0.05 value) is to be used. A multi-year model could be solved at one go or by rolling through several solves where each solve has a foresight horizon and a realisation horizon as can be seen from the figure below. In this example, the model rolls through several solves and therefore, in the figure above, the model object flexTool has four values in the solves array. Each value respresents one solve and it's position in the sequence of solves. Next figure shows the values needed to define one solve (out of the four solves in the example). All of these need to be repeated for each solve in the model. years_represented parameter is used by the model to calculate the discounting factors for the periods in the model (often future years). It should state the number of years each period will be representing. For example, a period for 2025 could represent the years 2025-2029 if its years_represented is set to 5. Any investments would be take place at the start of 2025 and discounted to the beginning of 2025, but the operational costs would accrue from each year in 2025-2029 each with a different discounting factor (decreasing based on interest rate). invest_periods parameter says in which periods the model is allowed to make investments realized_periods parameter states the periods that will be realized in this solve (results output) period_timeblockset defines the set of representative 'periods' (timeblocks in FlexTool) to be used in each FlexTool period .","title":"Multi-year model"},{"location":"tutorial/#discount-calculations","text":"Each asset that can be invested in should have invest_cost , lifetime and interest_rate parameters set and could have an optional fixed_cost . These are used to calculate the annuity of the investment. Annuity is used to annualize the investment cost, since FlexTool scales all costs (operational, investment and fixed) to annual level in order to make them comparable. Annuity is calculated as follows: invest_cost * interest_rate / { 1 - [ 1 / ( 1 + interest_rate ) ] ^ lifetime } + fixed_cost The next step is to consider discounting - future is valued less than the present. There is a model-wide assumption for the discount_rate . By default it is 0.05 (i.e. 5%), but it can be changed through the discount_rate parameter set for the flexTool model object. Discount factor for every period in the model is calculated from the discount_rate using the years_represented parameter of each solve , which how many years the period represents. Values for years_represented are used to calculate how many years_from_solve_start each year is. The formula is: [ 1 / ( 1 + discount_rate ) ] ^ years_from_solve_start Operational costs are also discounted using the same discount_rate . However, with operational costs it is assumed that they take place on average at the middle of the year whereas investment costs are assumed to take place at the beginning of the year (they are available for the whole year). These can be tweaked with the discount_offset_investments and discount_offset_operations parameters (given in years). Please note that given this formulation, invest_cost should be the overnight built cost (as is typical in energy system modelling, the model does not assume any construction time - the financing costs of the construction period need to be included in your cost assumptions). The model has a model horizon based on the years_represented parameters. The model will not include discounted investment annuities after the model horizon (in other words, the investments are 'returned' at the end of the model horizon). Naturally also operational costs are included only until the end of the model horizon. Finally, the retirements work similar to investments using the same discount_rate and interest_rate parameters but with salvage_value as the benefit from retiring the unit.","title":"Discount calculations"}]}